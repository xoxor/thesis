\begin{abstract}
	A social choice rule aggregates the preferences of a group of individuals over a set of alternatives into a collective choice. The literature admits several \acp{SCR} whose recommendations are supposed to reflect a compromise among individuals. We observe that all these compromise rules can be better described as \emph{procedural compromises}, i.e., they impose over individuals a willingness to compromise but they do not ensure an outcome where everyone has effectively compromised. We revisit the concept of a compromise in a collective choice environment with at least three individuals having strict preferences over a finite set of alternatives. Referring to a large class of spread measures, we view the concept of compromise from an \emph{equal loss} perspective, favoring an outcome where every voter concedes as equally as possible. As such, being a compromise may fail Pareto efficiency, which we ensure by asking voters to concede as equally as possible among the Pareto efficient alternatives. We show that Condorcet consistent rules, scoring rules and Brams-Kilgour compromises all fail to ascertain an outcome which is a compromise. This failure prevails for social choice problems with two individuals: all well-known two-person social choice rules of the literature, namely, fallback bargaining, Pareto and veto rules, short listing and veto rank, fail to pick ex-post compromises. 
\end{abstract}

\section{Introduction}
\label{sec:introduction}
In a typical social choice problem, several individuals express their preferences over a set of alternatives and one shall be picked as the collective outcome. Although the literature admits several \acp{SCR} with different properties, there is a common understanding that collective choices must reflect “compromises”. One of the first to explicitly refer to a \ac{SCR} as a compromise is \citet{Sertel1986} introducing the \emph{majoritarian compromise}. This \ac{SCR}, further analysed by \citet{Sertel1999}, is a rediscovery of a method suggested by James W.\ Bucklin at the beginning of the \nth{20} century \citep{Erdelyi2015}. Starting from everyone’s ideal alternative, it falls back to the voters’ second, third and more generally $k$-\emph{th} best, until one of the alternatives considered appears among the first $k$ best for a majority. \citet{Brams2001} generalise this concept and introduce a class of \acp{SCR} called $q$\emph{-approval fall-back bargaining}, where $q$ is the required quantity of support that can vary from a single voter up to unanimity. Different choices of $q$ lead to different \acp{SCR}. Considering $m$ alternatives, the choice of $q=1$ corresponds to the plurality rule, $q=\frac{m}{2}+1$ coincides with the majoritarian compromise and $q=m$ represents a bargaining procedure called \emph{fall-back bargaining}, which has been further analysed by \citet{Kibris2007} and \citet{Congar2012}. We will refer to these rules as Brams and Kilgour (BK) compromises with threshold q.

As \citet{OezkalSanver2004} discuss, the concept of compromising is mostly understood as the trade off between the number of voters supporting an alternative (i.e., the quantity of support) and the distance of that alternative from the supporters’ ideal alternative (i.e., the quality of support). This trade off, which is explicit for $q$-approval fall-back bargaining, is also the basis for several other \acp{SCR} such as the \emph{median voting rule} proposed by \citet{Bassett1999} and further analysed by \citet{Gehrlein2003} or the \emph{Condorcet practical method} described by \citet{Nurmi1999}. \Citet{Merlin2019} identify and analyse a large class of \emph{compromise rules} that explore this trade off.

One can argue that a collective choice \emph{per se} implies a compromise. After all, except extreme cases such as dictatorships,
a \acp{SCR} operates on the principle that all voters could fall back from their ideal position. Whether all voters effectively do fall back and whether this fall is “equal among voters” is the subject of our analysis. In what follows, we will present examples where they do not, which could be considered counter to the spirit of compromising. \footnote{This objection to the compromise nomenclature was raised by Jean-François Laslier during a CNRS workshop on compromising hosted by Istanbul Bilgi University in 2018.}

Consider the following example.
\begin{example}
	\label{ex:ex1}
	Let $N$ be a set of $n ≥ 3$ voters and $A$ a set of alternatives. $\linors$ represents the set of linear orders over $A$. Consider the following preference profile $P\in \linors^{N}$,
	\begin{center}
		$
		\begin{array}{cccc}
			\mathbf{1} \quad &c&b&a\\
			\mathbf{n-1} \quad &a&b&c\\
		\end{array}\quad ,
		$
	\end{center}
	which represents one individual who prefers $c$ to $b$, $b$ to $a$, hence $c$ to $a$; and $n-1$ individuals who prefer $a$ to $b$, $b$ to $c$, hence $a$ to $c$. At $P$, all BK compromises, except when $q=n$ (i.e. fall-back bargaining), will ignore the single voter and will pick $a$ as the collective outcome.
\end{example}

As a matter of fact, almost every \ac{SCR} will ignore this “marginal minority” and choose $a$ in this situation. While this choice is defensible on the grounds of qualified majoritarianism, it is questionable whether $a$ can be qualified as a compromise. Observe that $b$ receives unanimous support when each voter falls back one step from his ideal point. The question becomes more compelling when $a$ remains the collective choice even if the ignored group is much larger.

\begin{example}
	\label{ex:ex2}
	Consider the following preference profile with $n=100$:
	\begin{center}
		$
		\begin{array}{cccc}
			\mathbf{49} \quad &c&b&a\\
			\mathbf{51} \quad &a&b&c\\
		\end{array} \quad.
		$
	\end{center}
	When $q\in \intvl{1,\frac{n}{2}+1} $, all BK compromises pick $a$, and, again, it does not appear as a compromise as 51 voters reach their best alternative while the remaining 49 voters have to be contented with their worst one. 
\end{example}

Observe that all these \acp{SCR} impose to voters a willingness to compromise, but do not effectively ensure a compromise as the collective choice. In fact, the term “compromise” in this literature refers to procedural compromises that differ from outcome oriented compromises, a conceptual distinction that seems to be overlooked in the literature.
This can also be viewed as a distinction between ex-ante and ex-post compromises, where the profile is the source of uncertainty.

To define an ex-post compromise, we adapt a concept of equal losses that considers allocation of continuous utilities. This principle is used for bargaining \citep{Chun1988, Chun1991} and bankruptcy problems \citep{Herrero2001}. 
We introduce two definitions of compromise. In both of them, we pick a spread measure that determines how equally a given vector of real numbers is distributed and we propose to make a collective choice where voters give up from their ideal points “as equally as possible”. The difference between the two is that one, called \emph{egalitarian compromise}, insists on equality at the expense of Pareto efficiency while the other, called \emph{Paretian compromise}, is constrained to pick among the Pareto efficient alternatives. 
The two concepts are logically incompatible. As a result, Pareto efficient \acp{SCR} cannot ensure egalitarian compromises under any spread measure. We prove that several well-known \acp{SCR} such as Condorcet extensions, scoring rules, $q$-approval fall-back bargaining, all fail to be Paretian compromises under any spread measure. We provide examples for which being a Paretian compromise would necessitate to pick an alternative that is, although Pareto optimal, ranked very low by all voters. Such alternative would never be picked by any of the above-mentioned \acp{SCR}. 

We conclude that the equal-loss principle appears adequate for collective choice problems with at least three individuals, when egalitarianism, in the sense of conceding equally, is a major concern. Imagine a situation where the head of a laboratory needs to decide which project to fund and she asks for the preferences of the laboratory members. The workplace harmony is extremely important and, in order to avoid conflicts, the winning project must be equally supported by all members. 

Consider now a situation with only two voters. As the vast literature on the ultimatum game \citep{Werner2014} suggests, mutual consent is hard to obtain when one individual sees injustice at the levels of mutual losses. The equal-loss principle seems to be crucial in this new scenario.

Collective choice models with two individuals can be interpreted as bargaining or arbitration problems. While the bargaining interpretation necessitates an explicitly defined disagreement outcome \citep{Kibris2007}, the arbitration interpretation \citep{Sprumont1993} remains within the classical collective choice environment with no explicit disagreement outcome. In this paper, we consider the latter interpretation. 

Arbitration rules are thoroughly discussed by \citet{Barbera2020}. As prominent examples, we have fallback bargaining proposed by \citet{Brams2001}, the veto-rank and short listing procedures analysed by \citet{Clippel2014} and the Pareto-and-veto rules analysed by \citet{Laslier2020}. These models consider discrete alternatives which are not contained by the classical \citet{Nash1950} bargaining environment with convex utilities. We make the same assumption. However, as \citet{Mariotti1998} and \citet{Nagahisa2002} illustrate, the two worlds can be interconnected, as we do for the equal-loss principle of \citet{Chun1988} and \citet{Chun1991}. The arbitration environment presents an instance where envy-freeness could matter and it is rather surprising to discover that most interesting \acp{SCR} used as arbitration solutions fail to be Paretian compromises.

The rest of the paper is organised as follows. Section 2 presents the basic notions and notation. Section 3 introduces egalitarian compromises and Paretian compromises, two concepts that turn out to be logically incompatible. Section 4 shows that with at least three individuals, many \acp{SCR} fail to pick a compromise. Section 5 considers the two-individual case, showing that most \acp{SCR} of the literature fail to pick compromises. Section 6 makes some concluding remarks. 

\section{Basic notions and notation}
\label{sec:notation}
Consider a finite set $N$ of individuals with $\#N=n\geq 2$ and a finite set $A$ of alternatives with $\#A=m\geq 3$. We write $\linors$ for the set of linear orders over $A$.
A generic element $\prefi$ of $\linors$ stands for a preference of $i\in N$. This implies that, given any $x ≠ y\in A$, precisely one of $x \prefi y$ and $y\prefi x$ holds while $x \prefi x$ holds for no $x\in A.$ Moreover, $x\prefi y$ and $y\prefi z$ implies $x\prefi z$ $\forall x,y,z\in A$.

A \emph{profile} $P: N → \linors$ associates with each individual $i \in N$ a preference $P(i) = {\prefi}$. A \emph{\acl{SCR}} (\acs{SCR}) is a mapping $f:\linors^{N}\rightarrow 2^{A} \setminus \{\emptyset \}$. 

We write $r_{\prefi}(x)=\#\{y\in A \suchthat y \prefi x\}+1$ for the \emph{rank} of $x\in A$ at ${\prefi} \in \linors$. We denote by $\lambda_{\prefi}(x)=r_{\prefi}(x)-1$ the loss in terms of ranks for $i\in N$ with preference $\prefi$, when $x$ is elected instead of the best alternative
for $i$. The mapping $\lambda_P: A → \alllosses$ assigns to each $x\in A$ the loss vector $\lambda_{P}(x)=(\lambda_{\prefi}(x))_{i\in N}$ induced by the election of $x$. The double brackets denote intervals in the integers.

We are interested in measuring the spread of loss vectors. To this end, we define a \emph{spread measure} $\sigma: \alllosses → \R_{+}$ as a function that associates a spread value to every possible loss
vector. We write $\Sigma$ for the set of spread measures $\sigma$ that satisfy, for every $l\in\alllosses$, $\sigma(l)=0 ⇔ l_{i}=l_{j}$ $\forall i,j\in N$. Thus, the spread of $l$ gets its lowest value $0$ in case of perfect equality and only in this case. 

Given any distinct $x,y\in A$, we say that $x$ \emph{Pareto dominates} $y$ at $P \in\linors^{N}$ (or equivalenty $y$ is \emph{Pareto dominated} by $x $ at $P$) iff $x\prefi y,\forall i\in N$. We denote by
$\paretopt(P)= \set{x \in A \suchthat \forall y ≠ x \in A, \exists i \in N \suchthat x \pref_i y}$ the set of \emph{Pareto optimal} alternatives at $P$.
A \ac{SCR} $f$ is \emph{Paretian} iff $f(P)\subseteq\paretopt(P)$ $\forall P\in\linors^{N}$.

\section{Egalitarian versus Paretian compromises}
\subsection{Egalitarian compromises}
\label{sec:EgCompromise}
We denote the minimal elements of $X \subseteq A$ according to $(\sigma\circ\lambda_{P})$ with \break $\argmin_{X}(\sigma~\circ~\lambda_P)=\set{x \in X \suchthat \forall y \in X: \sigma(\lambda_P(x)) ≤ \sigma(\lambda_P(y))}$. Thus, $\argmin_{X}(\sigma\circ\lambda_{P})$ denotes the alternatives in X whose loss vectors are the most equally distributed according to the spread measure $\sigma$.

In what follows, we define some classes of \acp{SCR} that we are interested in analysing. 


\begin{definition} A \ac{SCR} $f$ is an \ac{EC} iff \[\exists \sigma \in \Sigma \suchthat \forall P \in \linors^N \text{ we have }f(P) \subseteq \musigma.\]
\end{definition}

\begin{definition} A \ac{SCR} $f$ is \ac{ECC} iff \[\exists \sigma \in \Sigma \suchthat \forall P \in \linors^N \text{ we have } f(P) \cap \musigma \neq \emptyset.\]
\end{definition}

Under a \ac{SCR} that is \ac{EC} (resp., \ac{ECC}), \emph{all} (resp., \emph{some}) winners are among the alternatives with most equally distributed losses. Clearly, \ac{EC} is a subclass of \ac{ECC}. Perhaps less obviously, being \ac{ECC} (or \ac{EC}) is incompatible with being Paretian. This will be deduced from the following proposition, which will also be useful to prove other theorems.% \cref{th:incompatibility}.


\begin{proposition} \label{prop:muSigmaLast}
	For $n ≥ 2, m ≥ 3$, there exists a profile $P \in \linors^N$ and an alternative $a_m$ such that $\forall i \in N$: $r_{\prefi}(a_m)=m$, and such that $\forall \sigma \in \Sigma: \musigma = \set{a_m}$; hence, $\musigma \cap \paretopt(P) = \emptyset$.
\end{proposition}
\begin{proof}
	Consider the following profile $P$:
	\begin{center}
		$
		\begin{array}{cccccc}
			\mathbf{1} \quad &a_1&a_2&\dots&a_{m-1}&a_m\\
			\mathbf{n-1} \quad &a_{\pi_(1)}&a_{\pi_(2)}&\dots&a_{\pi_(m-1)}&a_m\\
		\end{array}
		$ \quad,
	\end{center}
	where $\pi$ is the following permutation over $\intvl{1, m-1}$:
	\[
	\pi(i) = 
	\begin{cases}
		i+1 & \text{if } i \in \intvl{1, m-2} \\
		1 & \text{if } i = m-1
	\end{cases} \quad .
	\]
	In $P$, $a_m$ is the only alternative such that $r_{\prefi}(a_m)$ is independent of $i$; hence, $\sigma(\lambda_P(a)) > 0$, $\forall a \in A\setminus \{a_m\}$, $\forall \sigma \in \Sigma$. Thus, the set $\musigma$ consists of the sole element $a_m$, and, because $a_m$ is Pareto dominated, $\musigma \cap \paretopt(P) = \emptyset$.
\end{proof}

Our main result for \cref{sec:EgCompromise} follows easily.
\begin{theorem} \label{th:nonParetian}
	For $n\geq 2, \ m\geq3$, no Paretian \ac{SCR} is \ac{ECC}.
\end{theorem}
\begin{proof}
	Proving this amounts to show that $\forall \sigma \in \Sigma, \exists P \in \linors^N \suchthat \paretopt(P) \cap \musigma = \emptyset$. Suffices to use \cref{prop:muSigmaLast}, which asserts that there exists a profile $P$ such that $\forall \sigma \in \Sigma: \musigma \cap \paretopt(P) = \emptyset$.
\end{proof}

\subsection{Paretian compromises}
Having seen the tension for a \ac{SCR} being Paretian and \ac{ECC}, we investigate the consequences of inverting the order of priorities by insisting that at least some of the winning alternatives are Pareto optimal, and considering the most equally distributed loss vectors among those.

We consider two classes of \acp{SCR}. 
Observe that $\mustar$ denotes the set of Pareto optimal alternatives whose loss vectors are the most equally distributed according to the spread measure $\sigma$.

\begin{definition} A \ac{SCR} $f$ is a \ac{PC} iff \[\exists \sigma \in \Sigma \suchthat \forall P \in \linors^N \text{ we have } f(P) \subseteq \mustar.\]
\end{definition}

\begin{definition} A \ac{SCR} $f$ is \ac{PCC} iff \[\exists \sigma \in \Sigma \suchthat \forall P \in \linors^N \text{ we have } f(P) \cap \mustar \neq \emptyset.\]
\end{definition}

Again, it is clear that \ac{PC} is a subclass of \ac{PCC}. It will also probably come with no surprise that for a \ac{SCR}, being \ac{PC} is incompatible with being \ac{ECC}, as being \ac{PC} requires to be Paretian, which permits to use \cref{th:nonParetian}. On the other hand, it is less immediate that being \ac{EC} is incompatible with
being \ac{PCC}, because being \ac{PCC} does not require to be Paretian. This is however true.

\begin{theorem} \label{th:incompatibility} 
	For $n ≥ 2, m ≥ 3$, no \ac{SCR} is both \ac{EC} and \ac{PCC}.
\end{theorem}
\begin{proof}	
	Considering the profile $P$ of \cref{prop:muSigmaLast}, with $a_m$ the alternative mentioned there, any \ac{EC} $f$ and any $\sigma \in \Sigma$, suffices to prove that $f(P) \cap {\mustar[\sigma][P]} = \emptyset$.
	
	First, from \cref{prop:muSigmaLast} we have that
	$\set{a_m} \cap \paretopt(P) = \emptyset$, hence $\set{a_m} \cap$ \break $ {\mustar[\sigma][P]} = \emptyset$. 
	
	Second, because $f$ is \ac{EC}, for some $\sigmatop$, $f(P) \subseteq {\musigma[\sigmatop][P]}$. Using \cref{prop:muSigmaLast} again, we see that ${\musigma[\sigmatop][P]} = \set{a_m}$, hence $f(P) = \set{a_m}$.
	
	That $f(P) \cap {\mustar[\sigma][P]} = \emptyset$ follow from these two facts.
\end{proof}

It is interesting to note that the incompatibility is not complete, however.

\begin{remark}
	For $n ≥ 2$, $m ≥ 3$, there exist \acp{SCR} that are both \ac{ECC} and \ac{PCC}, such as the \ac{SCR} that selects the whole set of alternatives at every profile. However, this \ac{SCR} fails to be Paretian, as is any \ac{SCR} that is \ac{ECC}.
\end{remark}


\section{Which SCRs are compromises?}
\label{sec:more2voters}
In this section we assume $n\geq 3$ and leave the analysis of $n=2$ to the
next section.

\subsection{Condorcet consistent rules}

An alternative $x\in A$ is a \emph{Condorcet winner} at $P\in L(A)^{N}$ iff for all $y\in A \setminus \set{x} $, $\#\set{i \in N \suchthat x \prefi y} >\#\set{i \in N \suchthat y \prefi x}$. So each profile admits
either no or a unique Condorcet winner. An \ac{SCR} $f$ is \emph{Condorcet
	consistent} iff $f(P)=$ $\left\{ x\right\} $ at each $P\in L(A)^{N}$ that
admits $x$ as the unique Condorcet winner.

\begin{theorem} \label{th:condorcet}
	Let $n\geq 3$ and $m\geq 3$. A Condorcet consistent \ac{SCR} $f$ is neither \ac{ECC} nor \ac{PCC}.
\end{theorem}
\begin{proof}
	Consider the following profile $P$, where the dots represent the sequence $a_4$ to $a_m$:
	\begin{center}
		$
		\begin{array}{cccccc}
			\mathbf{n-1} \quad &a_1&a_2&a_3&\dots\\
			\mathbf{1} \quad &a_3&a_2&\dots&a_1\\
		\end{array}
		$ \quad.
	\end{center}
	
	Consider any Condorcet consistent \ac{SCR} $f$. Thus, $f(P)=\{a_1\}$. However, $\musigma=\mustar=\{a_2\}$ $\forall \sigma \in \Sigma$, so there exists a profile $P$ such that both $f(P)\cap \musigma$ and $f(P)\cap \mustar$ are empty.
\end{proof}

Note that Condorcet consistent rules need not be Paretian so the fact that they all fail \ac{ECC} does not follow from \cref{th:nonParetian}. 

\subsection{Scoring rules}
\label{sec:scoringrules}
A \emph{score vector} is an $m-$tuple $w=(w_{1},\dots,$ $w_{m})\in \intvl{0, 1}^{m}$ with $w_{1}=1$, $w_{m}=0$ and $w_{i}\geq w_{i+1}$ $\forall i\in \intvl{1, m-1}$. Given a score vector $w$, we write $s^{w}(x,P)=\sum_{i\in N}w_{r_{\prefi}(x)}$ for the score of $x\in A$ at $P\in L(A)^{N}$. Each vector $w$ identifies a \emph{scoring rule} $f^w_n$ defined as $f^w_n(P)=\left\{ x\in A:s^{w}(x,P)\geq s^{w}(y,P) \ \forall y\in A\right\}$ for every $P\in L(A)^{N}$.

We first show that no scoring rule is \ac{ECC}, for any value of $n$ and $m$ at least 3.

\begin{theorem}\label{th:srECC}
	Let $n\geq 3$ and $m\geq 3.$ No score vector $w$ induces a scoring rule $f^w_n$ that is \ac{ECC}.
\end{theorem}
\begin{proof}
	Take any score vector $w$. Consider the profile $P$ of \cref{prop:muSigmaLast}. Observe that $\musigma=\{a_m\} \ \forall \sigma \in \Sigma $. However, as $w_{1}>w_{m}$, we have $s^{w}(a_{1},P)>s^{w}(a_{m},P)$ which implies $a_{m}\notin f^{w}(P)$.
\end{proof}

We call antiplurality score vector the vector $w$ such that $w_{i} = 1, \forall i \in \intvl{1, m-1}$, and $w_{m}=0$.

\begin{theorem}
	\label{th:AntSatsPCC}
	Let $m\geq 3$ and let $w$ be the antiplurality score vector. The \ac{SCR} $f_{n}^{w}$ satisfies \ac{PCC} for all $n\geq 3$.
\end{theorem}
\begin{proof}
	Define $\bar\sigma \in \Sigma$ as, $\forall l \in \intvl{0,m-1}^N$: $\bar\sigma(l) = 1$ iff $\exists i, j \in N \suchthat l_i ≠ l_j$; $\bar\sigma(l) = 0$ otherwise.
	We show the non-emptyness of $f^w_n(P) \cap \mustar[\bar\sigma]$ for any profile $P$.
	
	Let $k = \min_{\paretopt(P)} \set{(\bar\sigma \circ \lambda_P)(x)}$ be the minimal value attained by $\bar\sigma \circ \lambda_P$ over $\paretopt(P)$. By construction of $\bar\sigma$, $k$ equals either $0$ or $1$.
	
	For $k = 1$, take any $x \in f^w_n(P) \cap \paretopt(P)$, which exists because the antiplurality rule, although not Paretian, never picks only non-Pareto optimal alternatives. 
	By definition of $\bar\sigma$, $\bar\sigma(x) ≤ 1$, hence, $x \in \mustar[\bar\sigma]$.
	%	We then have that $x \in \mustar[\bar\sigma]$ as by definition of $\bar\sigma$, $\bar\sigma(x) ≤ 1$.
	
	For $k = 0$, take any $x \in \mustar[\bar\sigma]$. As $\bar\sigma (\lambda _{P}(x))=0$, we have, $\forall i, j \in N$: $\lambda_i^P(x) = \lambda_j^P(x)$, hence, $\forall i, j \in N$: $r_{\succ_i}(x) = r_{\succ_j}(x)$. 
	The case $r_{\succ_i}(x) = m, \forall i \in N$ is ruled out by $x \in \paretopt(P)$. Hence, $r_{\succ_i}(x) ≤ m - 1, \forall i \in N$, hence, $x \in f^w_n(P)$.
\end{proof}

It is worth noting that the antiplurality rule $f_{n}^{w}$ is not Paretian, hence fails \ac{PC}  for all $n\geq 3$. This can be seen by picking a unanimous profile $P\in \linors^{N}$ with $a_{1}\prefi a_{2}\prefi \dots \prefi a_{m}$ $\forall i\in N$, where $\mustar=\left\{ a_{1}\right\} \forall \sigma \in \Sigma $ while $f_{n}^{w}(P)=A \setminus \left\{ a_{m}\right\}$.

\begin{theorem}
	\label{th:srPCC}
	Let $m\geq 3.$ Take any score vector $w$ which is not the antiplurality score vector. For some $n ≥ 3$, the \ac{SCR} $f_{n}^{w}$ fails \ac{PCC}.
\end{theorem}

\begin{proof}
	Take any $m\geq 3$ and any score vector $w$ that is not the antiplurality score vector; therefore, $w_{m-1}<1$. Pick any $n$ such that $n ≥ m - 1$ and $n > \frac{1}{1 - w_{m - 1}}$. Consider a profile $P\in L(A)^{N}$
	
	\begin{center}
		$
		\begin{array}{cccccc}
			i = 1 \quad & a_2 & … & a_m & a_1\\
			2 ≤ i ≤ m - 2 \quad & a_1 & … & a_m & a_i\\
			m - 1 ≤ i ≤ n \quad & a_1 & … & a_m & a_{m-1}\\
		\end{array}
		$\quad,
	\end{center}
	where all alternatives except $a_m$ appear at least once in the last rank.
	Thus, for every $\sigma \in \Sigma$, we have 
	$\sigma (\lambda _{P}(x))>0$ $\forall x\in A \setminus \left\{ a_{m}\right\}$
	while
	$\sigma (\lambda_{P}(a_{m}))=0$. 
	Moreover, $a_{m}\in \paretopt(P)$. Thus, $\mustar=\left\{ a_{m}\right\} $ $\forall \sigma \in \Sigma $. On the other hand, $s^{w}(a_{1}; P)=n-1$, $s^{w}(a_{m}; P)=n\cdot w_{m-1}$ and
	as $n > \frac{1}{1 - w_{m - 1}}$ (or, equivalently, $n - 1 > n w_{m - 1}$), we have $s^{w}(a_{1}; P)>s^{w}(a_{m};$ $P)$,
	establishing $a_{m}\notin f^{w}(P)$, thus $f^{w}(P)\cap \mustar=\emptyset $ $\forall \sigma \in \Sigma $.
\end{proof}

\subsection{BK compromises}
\label{sec:BKn3}
Given any $k\in \intvl{1, m}$, we write $n_{k}(x,P)=\#\{i\in
N\mid r_{\prefi}(x)\leq k\}$ for the \emph{$k$-support} that $x$ gets at $P$, that is, the number of individuals for whom the rank of alternative $x\in A$ is lower than or equal to $k$ in the profile $P\in $ $L(A)^{N}$.
Note that $n_{k}(x,P)\in \intvl{1, n}$ is non-decreasing on $k$ and $n_{m}(x,P)=n.$ For each $q\in \intvl{1,n}$, we define $\rho_{q}(x,P)=\min \{k\in \intvl{1,m} \suchthat n_{k}(x,P)\geq q\}$ as the minimal rank $k$ at which the $k$-support that $x$ gets at $P$ is at least $q$. We
write $\rho _{q}(P) = \min_{x \in A} \set{\rho_{q}(x, P)}$ for the minimal rank $k$ at which the $k$-support that some alternative gets at $P$ is at least $q$. \emph{A Brams and Kilgour (BK) compromise with threshold }$q$ is the
\ac{SCR} $f_{q}$ defined for each $P\in \linors^N$ as $f_{q}(P)=\{x\in A \suchthat n_{\rho _{q}(P)}(x,P)\geq n_{\rho _{q}(P)}(y,P)$ $\forall y\in A\}.$ 

\begin{theorem}
	\label{th:FBsatsPC}
	Let $n\geq 3$ and $m\geq 3.$ The BK compromise $f_{n}$ satisfies \ac{PC}.
\end{theorem}

\begin{proof}
	Define $\bar{\sigma } \in \Sigma$ as, $\forall l \in \intvl{0,m-1}^N$: $\bar\sigma(l) = 1$ iff $\exists i, j \in N \suchthat l_i ≠ l_j$; $\bar\sigma(l) = 0$ otherwise.
	Considering any $x \in f_n(P)$, let us show that $x \in \mustar[\bar{\sigma}]$. Because $x \in f_n(P)$, $x \in \paretopt(P)$, and therefore, suffices to show that $\forall y \in \paretopt(P)$, $\bar{\sigma}(\lambda_P(y)) ≥ \bar{\sigma}(\lambda_P(x))$. Given the choice of $\bar{\sigma}$, picking any $y \in \paretopt(P)$ with $y≠x$, suffices to show that $\bar{\sigma}(\lambda_P(y)) = 1$, equivalently, that $\exists i, j \in N \suchthat r_{\prefi}(y) ≠ r_{\pref_j}(y)$. 
	Because $x \in f_n(P)$, $\rho_n(P) = \rho_n(x, P) = \max_{N} r_{\prefi}(x)$.
	It follows from $\rho_n(P) = \min_{z \in A} \set{\rho_n(z, P)}$ that $\rho_n(y, P) ≥ \rho_n(x, P)$, thus, $\exists i \in N \suchthat r_{\prefi}(y) ≥ \rho_n(P)$. 
	Also, $y \in \paretopt(P)$ implies that $\exists j \in N \suchthat r_{\pref_j}(y) < r_{\pref_j}(x)$, thus $\exists j \in N \suchthat r_{\pref_j}(y) < \rho_n(P)$. 
	Therefore, $r_{\prefi}(y) ≠ r_{\pref_j}(y)$.
\end{proof}

\begin{theorem}
	\label{th:FBfailsECC}
	Let $n\geq 3$ and $m\geq 3.$ The BK compromise $f_{n}$ fails \ac{ECC}. 
\end{theorem}
\begin{proof}
	As $f_{n}$ is Paretian, the proof comes straightforward from \cref{th:nonParetian}.
\end{proof}

\begin{theorem}
	\label{th:BKthreshold}
	Let $n\geq 3$ and $m\geq 3.$ A BK compromise $f_{q}$ with threshold $q \in \intvl{1, n-1}$ is neither \ac{ECC} nor \ac{PCC}.
\end{theorem}
\begin{proof}
	%Take any $n\geq 3$ and $m\geq 3.$ Let $A=\left\{ a_{1},\text{ }a_{2,}...
	%\text{ }a_{m}\right\} $. Pick some $q\in \left\{ 1,...,n\right\} $ and
	%consider the BK compromise $f_{q}$. 
	Consider the following profile $P$ (also used in the proof of \cref{th:condorcet}), where the dots represent the sequence $a_4$ to $a_m$:
	\begin{center}
		$
		\begin{array}{cccccc}
			\mathbf{n-1} \quad &a_1&a_2&a_3&\dots\\
			\mathbf{1} \quad &a_3&a_2&\dots&a_1\\
		\end{array}
		$\quad.
	\end{center}
	We have that $f_{q}(P)=\{a_1\}$, and, because $\sigma(\lambda_P(a_2)) = 0$ and $\sigma(\lambda_P(a_1)) > 0$, neither $\musigma$ nor $\mustar$ contain $a_1$ for any $\sigma \in \Sigma$. 
	%Remzi’s proof
	%Take any $n\geq 3$ and $m\geq 3.$ Let $A=\left\{ a_{1},\text{ }a_{2,}...%
	%\text{ }a_{m}\right\} $. Pick some $q\in \left\{ 1,...,n\right\} $ and
	%consider the BK compromise $f_{q}$. Consider the profile $P\in L(A)^{N}$ such that 
	%$a_{1}\succ _{i}a_{2}\succ _{i}...\succ _{i}a_{m}$ $\forall i\in N\diagdown
	%\left\{ n\right\} $ and $a_{\pi (1)}\succ _{n}a_{\pi (2)}\succ _{n}...\succ
	%_{n}a_{\pi (m)}$ where $\pi $ is a bijection on $\left\{ 1,\text{ }2,...,%
	%\text{ }m\right\} $ with $\pi (1)=3$, $\pi (2)=2,\pi (3)=1$, $\pi (i)=i+1$ $%
	%\forall i\in \left\{ 4,...,\text{ }m-1\right\} $ and $\pi (m)=4 $, we have $%
	%f_{q}(P)=\left\{ a_{1}\right\} $ while $\mu _{\sigma }(P)=\mu _{\sigma
	%}^{\ast }(P)=\left\{ a_{2}\right\} $ $\forall \sigma \in \Sigma $.
\end{proof}

\subsection{Restrictions on sigma}
\label{sec:RestrictionOnSigma}
The perfect equality recognition condition we adopt for spread measures, i.e., that the spread gets its lowest value $0$ in case of perfect equality and only in this case, is very basic. Unless this condition is violated, $\Sigma$ is the largest set of spread measures we could conceive. On the other hand, it is possible to let $\Sigma$ shrink by imposing additional conditions over spread measures. Nevertheless, as the satisfaction of \ac{PC}, \ac{PCC}, \ac{EC}, or \ac{ECC} requires the existence of a spread measure, all of our negative results, namely, those expressed by \cref{th:nonParetian,,th:incompatibility,,th:condorcet,,th:srECC,,th:srPCC,th:FBfailsECC,th:BKthreshold} prevail when $\Sigma$ is restricted. In a similar vein, the positive results in \cref{th:AntSatsPCC,th:FBsatsPC} risk to be lost with additional conditions over spread measures.
Indeed, this section shows that a mild restriction removes the positive results concerning the only two rules that we found to be compatible with any of our compromise concepts.

\begin{definition}
	\label{def:conditionC}
	Given any $m\geq4$ and $n\geq \max\{4,m-1\}$, we say that a spread measure $\sigma$ satisfies condition $C_{m,n}$ iff we have $\sigma(m-3, m-1, m-2, \dots, m-2) < \sigma(m-2, m-3, \dots, 1, 0, \dots, 0)$.
\end{definition}

As both vectors are $n$ dimensional, the term $m-2$ repeats $n-2$ times in the first vector and the term $0$ repeats $n-m+2$ times in the second vector.

This condition imposes a very reasonable requirement on spread measures for large values of $m$ and $n$. Asking for $\sigma(1,3,2,2)$ to be smaller than $\sigma(2,1,0,0)$ is demanding while asking for $\sigma(5,7,6,6,6,6,6)$ to be smaller than $\sigma(6,5,4,3,2,1,0)$ reflects a mild assumption. In any case, as we state below, several well-known spread measures of the literature (see \citet{Allison1978} for a comprehensive account) satisfy \cref{def:conditionC}. Letting $\bar{l} = \sum_{i=1}^{n} l_i / n$ denote the arithmetic mean of the values of $l = (l_1, …, l_n)$, we consider the following measures:

\begin{itemize}
	\item the mean absolute difference $\sigma_{mad}(l)= \frac{1}{n^2} \sum_{i=1}^{n}\sum_{j=1}^{n}|l_i-l_j|$;
	\item the average absolute deviation $\sigma_{ad}(l)= \frac{\sum_{i=1}^{n}|l_i-\bar{l}|}{n}$;
	\item the standard deviation $\sigma_{sd}(l)= \sqrt{\frac{\sum_{i=1}^{n}(l_i-\bar{l})^2}{n}}$;
	\item the Gini coefficient $\sigma_{G}(l)= \frac{\sum_{i=1}^{n}\sum_{j=1}^{n}|l_i-l_j|}{2 \cdot n \cdot \sum_{i=1}^{n} l_i}$.
\end{itemize} 

\begin{remark}
	\label{prop:spreadMeas}
	We checked experimentally that $\sigma_{mad}$, $\sigma_{ad}$, $\sigma_{sd}$ and $\sigma_{G}$ all satisfy condition $C_{m,n}$, for $m \in \intvl{4,1000}$ and $n \in \intvl{b, 1000}$ where $b = \max\{4,m-1\}$.
\end{remark}

%\begin{remark}
%	\label{prop:spreadMeas}
%	$\sigma_{mad}$, $\sigma_{ad}$, $\sigma_{sd}$ and $\sigma_{G}$ all satisfy condition $C_{m,n}$, for $m \in \intvl{4,1000}$ and $n \in \intvl{b, 1000}$ where $b = \max\{4,m-1\}$.
%\end{remark}
%
%\begin{proof} for $\sigma_{mad}$. \\
%	\label{proof:sigmamad}
%	Recall that 
%	\[\sigma_{mad}(l)= \frac{1}{n^2} \sum_{i=1}^{n}\sum_{j=1}^{n}|l_i-l_j|.\]
%	Let us define $f_l(i)= \sum_{j}|l_i-l_j|$ and $s(l) = n^2 \smad(l)$. Thus $n^2 \sigma_{mad}(l) = s(l)= \sum_{i} f_l(i)$.
%	
%	Consider the two vectors $l_1=(m-3, m-1, m-2, \dots, m-2)$ (where $n-2$ terms are equal to $m-2$) and $l_2=\sigma(m-2, m-3, \dots, 1, 0, \dots, 0)$ (where $m-2$ terms go from $m-2$ to $1$, and $m-n+2$ terms are equal to $0$). 
%	The thesis is now that $s(l_1) < s(l_2)$.
%	
%	Let us consider $l_1$ first: 
%	\begin{align*}
%		&f_{l_1}(1)= 2+(n-2)=n \\
%		&f_{l_1}(2)= 2+(n-2)=n \\
%		&f_{l_1}(i)= 2 \quad \forall \ 3\leq i \leq n \\ 
%	\end{align*}
%	In fact, considering the first term of $l_1$ ($m-3$), the difference between itself and the second term of the vector ($m-1$) is $2$; the difference between itself and any of the other $n-2$ terms of the vector ($m-2$) is $1$. The sum of these differences is represented by $f_{l_1}(1)$. The same argument holds for the second term ($m-1$). Any of the remaining $n-2$ terms ($m-2$) has a difference $1$ with the first and the second term and a difference $0$ with the rest. Therefore 
%	\[s(l_1) =2(2+(n-2))+(n-2)\cdot2)= 4n-4\]
%	
%	To compute $s(l_2)$, let us distinguish the cases $1 ≤ i ≤ m - 2$ and $m - 1 ≤ i$.
%	
%	For $1 ≤ i ≤ m - 2$, 
%	\begin{align*}
%		f_{l_2}(i) &= \sum_{1 ≤ j ≤ i} |l_i - l_j| + \sum_{i < j ≤ m - 2} |l_i - l_j| + \sum_{m - 2 < j ≤ n} |l_i - l_j|\\
%		&= [(i - 1) + (i - 2) + … + 0] + [1 + … + (m - 2 - i)] \\
%		&\quad + (m - 1 - i) (n - m + 2)\\
%		%	[that’s i terms, then m - 2 - i terms, then n - m + 2 terms]
%		&= \frac{(i - 1) i}{2} + \frac{(m - 2 - i) (m - 1 - i)}{2} + (m - 1 - i) (n - m + 2)\\
%		&= i^2 / 2 - i / 2 + \frac{(m - 2) (m - 1) - i (m - 2 + m - 1) + i^2}{2} \\
%		&\quad + (m - 1) (n - m + 2) - i (n - m + 2)\\
%		&= i^2 - i \frac{1 + 2m - 3 + 2(n - m + 2)}{2} + (m - 1) \frac{m - 2 + 2 (n - m + 2)}{2}\\
%		&= i^2 - i (n + 1) + (m - 1) \frac{-m + 2n + 2}{2}.
%	\end{align*}
%	
%	For $m - 1 ≤ i$, $f_{l_2}(i) = m - 2 + m - 3 + … + 1 = \frac{(m - 2) (m - 1)}{2}$.
%	
%	Thus, 
%	\begin{align*}
%		s(l_2) &= \sum_{1 ≤ i ≤ m - 2}[i^2 - i (n + 1) + (m - 1) \frac{-m + 2n + 2}{2}] \\
%		&\quad + (n - (m - 2)) (m - 2) (m - 1) / 2\\
%		&= (m - 2) (m - 1) (2m - 3) / 6 - (n + 1) (m - 2) (m - 1) / 2 \\
%		&\quad + (m - 2) (m - 1) (- m + 2n + 2) / 2 \\
%		&\quad + (n - m + 2) (m - 2) (m - 1) / 2\\
%		%		&\quad + n (m - 2) (m - 1) / 2 - (m - 2)^2 (m - 1) / 2\\
%		&= (m - 2) (m - 1) \left(\frac{2m - 3}{6} - \frac{n + 1}{2} + \frac{- m + 2n + 2}{2} + \frac{n - m + 2}{2}\right)\\
%		%		&= (m - 2) (m - 1) \left(\frac{2m - 3}{6} + \frac{- 2m + 3 + 2n}{2}\right)\\
%		&= (m - 2) (m - 1) \left(\frac{-2m + 3}{3} + n\right).
%	\end{align*}
%	
%	Our thesis is now that 
%	\[4n - 4 < \frac{-2m + 3}{3} (m - 2) (m - 1) + n (m - 2) (m - 1)\]
%	or equivalently, that 
%	\[\frac{(2m - 3) (m - 2) (m - 1)}{3} - 4 < n [(m - 2) (m - 1) - 4].\]
%	
%	When $m = 4$, using the fact that $4 ≤ n$, the inequality holds: $5 (2) (3) / 3 - 4 < 4 [2] ≤ n [2]$.
%	
%	Now assume that $m ≥ 5$. Using the fact that $m - 1 ≤ n$, suffices to show that
%	$(2m - 3) (m - 2) (m - 1) / 3 - 4 < (m - 1) [(m - 2) (m - 1) - 4]$, or equivalently, that
%	$-12 < (m - 1) [3 (m - 2) (m - 1) - 12 - (2m - 3) (m - 2)]$.
%	Note that the right hand side equals $(m - 1) [(m - 2) (3 (m - 1) - (2m - 3)) - 12] = (m - 1) (m^2 - 2m - 12) = (m - 1) (m - 1 + \sqrt{13}) (m - 1 - \sqrt{13})$. As all multiplicands are positive when $m ≥ 5$, the inequality is true when $m ≥ 5$.
%\end{proof}		
%
%\begin{proof} for $\sigma_{ad}$. \\
%	Recall that 
%	\[\sigma_{ad}(l)= \frac{\sum_{i=1}^{n}|l_i-\bar{l}|}{n},\] 
%	where $\bar{l}=\frac{\sum_{i=1}^{n}l_i}{n}$.
%	Let us define $s(l)= \sum_{i}|l_i-\bar{l}|$, so that $s(l) = n \sigma_{ad}(l)$.
%	Consider the two vectors $l_1=(m-3, m-1, m-2, \dots, m-2)$ and $l_2=(m-2, m-3, \dots, 1, 0, \dots, 0)$. The thesis is now that $s(l_1) < s(l_2)$.
%	
%	For $l_1$, the arithmetic mean of its values is $m-2$, so 
%	\[s(l_1)=[|m-3-m+2|+|m-1-m+2|+ 0 + \dots + 0]= 2.\]
%	
%	For $l_2$, the arithmetic mean is 
%	\[\bar{l_2}=\frac{1}{n}\sum_{i=1}^{m-2}{i}= \frac{(m-2)(m-1)}{2n}.\]
%	Recall that 
%	\begin{align*}
%		\sum_{i=k}^{m}{i} &= \frac{(m+1-k)(m+k)}{2} \\
%	\end{align*}
%	We can write $s(l_2)$ as:
%	\begin{align*}
%		s(l_2)&= \sum_{i=1}^{m-2}{|i-\bltwo|}+(n-(m-2))|0-\bltwo|=\\
%		&= \sum_{i=1}^{m-2}{|i-\bltwo|}+(n-m+2)\bltwo=\\
%		&=\sum_{i=\fltwo+1}^{m-2}{(i-\bltwo)}-\sum_{i=1}^{\fltwo}{(i-\bltwo)} +(n-m+2)\bltwo=\\
%		&=\sum_{i=\fltwo+1}^{m-2}{i}-\sum_{i=\fltwo+1}^{m-2}{\bltwo}-\sum_{i=1}^{\fltwo}{i} +\sum_{i=1}^{\fltwo}{\bltwo}+(n-m+2)\bltwo=\\
%		&= -\frac{(\fltwo+1-m+2-1)(\fltwo+1+m-2)}{\fltwo}-(m-2-\fltwo-1+1)\bltwo\\ &-\frac{\fltwo(\fltwo+1)}{2}+\fltwo \bltwo + (n-m+2)\bltwo=\\
%		&=-\frac{(\fltwo-m+2)(\fltwo+m-1)}{2}-(m-2-\fltwo)\bltwo-\frac{\fltwo(\fltwo+1)}{2} \\
%		&+ \fltwo \bltwo + (n-m+2)\bltwo=\\
%		&=-\frac{(\fltwo)(\fltwo+m-1)}{2}+\frac{(m-2)(\fltwo+m-1)}{2} -(m-2)\bltwo+(\fltwo)\bltwo \\ &-\frac{\fltwo(\fltwo+1)}{2}+ \fltwo \bltwo + (n-m+2)\bltwo=\\
%		&=-\frac{(\fltwo)(\fltwo+m-1)}{2}+\frac{(m-2)\fltwo}{2}+\underbrace{\frac{(m-2)(m-1)}{2}}_{=n \bltwo} -(m-2)\bltwo \\ &-\frac{\fltwo(\fltwo+1)}{2}+ 2\fltwo \bltwo + (n-m+2)\bltwo=\\
%		&=\fltwo(-\frac{\fltwo+m-1}{2}+\frac{m-2}{2}-\frac{\fltwo +1}{2}+2\bltwo)+
%		2\bltwo(n-m+2)=\\
%		&=\fltwo(\frac{-\fltwo-m+1+m-2+4\bltwo-\fltwo-1}{2})+2\bltwo(n-m+2)=\\
%		&=\fltwo(\frac{4\bltwo-2\fltwo-2}{2})+2\bltwo(n-m+2)=\\
%		&=\fltwo(2\bltwo-\fltwo-1)+2\bltwo(n-m+2) \tag{1}\\
%	\end{align*}
%	\commentOC{Note that there must be an easier way of getting this result, or perhaps even a simpler one. Imagine I sum from 1 to 5 the distance to a value that would be $3.2$, I’d get $\abs{1 - 3.2} + \abs{2 - 3.2} + \abs{3 - 3.2} + \abs{4 - 3.2} + \abs{5 - 3.2} = 2.2 + 1.2 + 0.2 + 0.8 + 1.8$. Grouping the terms $1.2$ and $0.8$, and $0.2$ and $1.8$, I get $2.2 + 2 + 2$. That said, we do not absolutely need to obtain an easier development if we do not include it in our article, so you can leave this as is if you prefer. Just perhaps try to think a bit about it to see if it leads somewhere easily.}
%	
%	Define $\epsilon = \bar{l_2} - \floor{\bar{l_2}}$, thus $0 ≤ \epsilon < 1$. We can rewrite (1), by using the fact that $\floor{\bar{l_2}} = \bar{l_2} - \epsilon$, as:
%	\begin{align*}
%		(1)&= (\bltwo-\epsilon)(2\bltwo-(\bltwo-\epsilon)-1)+2\bltwo(n-m+2)=\\
%		&= (\bltwo-\epsilon)(\bltwo+\epsilon-1)+2\bltwo(n-m+2)=\\
%		&= (\bltwo-\epsilon)(\bltwo+\epsilon)-(\bltwo-\epsilon)+2\bltwo(n-m+2)=\\
%		&= \bltwo^2-\epsilon^2-\bltwo+\epsilon+2\bltwo n-2\bltwo m+4\bltwo=\\
%		&= \bltwo^2+2\bltwo n-2\bltwo m+3\bltwo+\epsilon-\epsilon^2\\
%	\end{align*}
%	\hfuzz=4cm
%	Define $\delta=\epsilon-\epsilon^2$ and recall that our thesis is now that $s(l_1)<s(l_2)$:
%	\begin{align*}
%		2&< \bltwo^2+2\bltwo n-2\bltwo m+3\bltwo+\delta\\
%		0&< \bltwo^2+2\bltwo n-2\bltwo m+3\bltwo+\delta-2\\
%		0&< \bltwo^2 n^2+2\bltwo n^3-2\bltwo m n^2+3\bltwo n^2+\delta n^2-2 n^2\\
%	\end{align*}
%	Define $p=\frac{(m-2)(m-1)}{2}=\bltwo n$, we can rewrite the inequality as: 
%	\begin{align*}
%		0&< p^2+2p n^2-2p m n+3p n+\delta n^2-2 n^2\\
%	\end{align*}
%	Because $0 \leq \delta < 1$ showing that the inequality holds for $\delta=0$ proves it for all $\delta$.
%	\begin{align*}
%		0&< p^2+2p n^2-2p m n+3p n-2 n^2\\
%		0&< n^2(2p-2)-n(2pm-3p)+p^2\\
%		0&< n^2((m-2)(m-1)-2)-n(2m-3)p+p^2\\
%		0&< n^2(m-3)m-n(m-3+m)p+p^2\\
%		0&< (mn-p)[(m-3)n-p]
%	\end{align*}
%	\commentOC{From here downwards, we are basically doing the same reasoning twice. It is enough to show that $(m - 3)n - p > 0$ as this is the smaller multiplicand among these two.}
%	\commentOC{Also, we could (almost) get rid of the special case $m = 4$. Just reason for when $n ≥ m - 1$ and afterwards, observe that when $m = 4$, then $n > m - 1$ (strictly) thus the inequality becomes strict.}
%	\commentOC{Or better, try out the following. Our thesis is $2(m - 3) n - (m - 2) (m - 1) > 0$. Define $n = (m - 1) + \alpha$. Observe that $\alpha ≥ 0$ and $\alpha > 0$ when $m = 4$. Divide by $m - 1$. I think that should be enough.}
%	When $m=4$, then $n\geq4$ and $p=3$ thus we have that $(4n-p)[(4-3)n-p]\geq(4 \cdot 4-3)[(4-3)4-3]=13>0$ \commentOC{“When $m=4$, then $n\geq4$” is confusing, because it reads as if we would know that $n ≥ 4$ because $m = 4$. But $n ≥ 4$ always holds, by hypothesis of our statement to be proven, it is not a consequence of $m = 4$. I suggest to write: When $m=4$, then $p=3$, thus, using the fact that $n ≥ 4$, we have that… And similarly for the next sentence.}. When $m\geq5$ then $n ≥ m - 1$ and we have that
%	\begin{align*}
%		(mn-p)[(m-3)n-p] \geq (m(m-1)-p)[(m-3)(m-1)-p]. 
%	\end{align*}
%	Consider the first multiplicand \commentOC{After the first line, just factor out $m - 1$ and obtain $(m - 1) (m - \frac{m - 2}{2})$, and I think you can jump to the conclusion.}:
%	\begin{align*}
%		m(m-1)-p &= m(m-1)-\frac{(m-2)(m-1)}{2}= \\
%		&=\frac{1}{2}(2m(m-1)-(m-2)(m-1))=\\
%		&=\frac{1}{2}((2m-m+2)(m-1))=\\
%		&=\frac{1}{2}(m+2)(m-1)
%	\end{align*}
%	which is always positive for $m\geq5$. Consider now the second term:
%	\begin{align*}
%		(m-3)(m-1)-p &= (m-3)(m-1)-\frac{(m-2)(m-1)}{2}= \\
%		&=\frac{1}{2}(2(m-3)(m-1)-(m-2)(m-1))\\
%		&=\frac{1}{2}(2m-6-m+2)(m-1)\\
%		&=\frac{1}{2}(m-4)(m-1)
%	\end{align*}
%	which is always positive for $m\geq5$. Therefore
%	\begin{align*}
%		(mn-p)[(m-3)n-p] \geq (m(m-1)-p)[(m-3)(m-1)-p] > 0 
%	\end{align*}
%	which concludes the proof.
%	
%\end{proof}
%
%\begin{proof} for $\sigma_{sd}$. \\
%	Recall that 
%	\[\sigma_{sd}(l)= \sqrt{\frac{\sum_{i=1}^{n}(l_i-\bar{l})^2}{n}}\]	
%	where $\bar{l}=\frac{\sum_{i=1}^{n}l_i}{n}$.
%	Let us define $s(l)= \sum_{i}^{n}(l_i-\bar{l})^2$, so that $s(l) = n \sigma_{sd}(l)^2$.
%	Consider the two vectors $l_1=(m-3, m-1, m-2, \dots, m-2)$ and $l_2=(m-2, m-3, \dots, 1, 0, \dots, 0)$. The thesis is now that $s(l_1) < s(l_2)$.
%	
%	For $l_1$, the arithmetic mean of its values is $m-2$ so $s(l_1)$: 
%	\[s(l_1)=(m-3-m+2)^2+(m-1-m+2)^2+ 0 + \dots + 0= 2\]
%	For $l_2$, the arithmetic mean is \commentOC{Please factor out the computation and results for $\bar{l_1}$ and $\bar{l_2}$, to avoid the repetition.}
%	\[\bar{l_2}=\frac{1}{n}\sum_{i=2}^{m-2}{i}= \frac{(m-2)(m-1)}{2n}.\]
%	Recall that 
%	\begin{align*}
%		\sum_{i=1}^{m}{i^2} &= \frac{m(m+1)(2m+1)}{6}
%	\end{align*}
%	%	Recall that 
%	%	\begin{align}
%	%		\sum_{i=k}^{m}{x} &= (m-k+1)x \\
%	%		\sum_{i=1}^{m}{i} &= \frac{m(m+1)}{2}\\
%	%		\sum_{i=1}^{m}{i^2} &= \frac{m(m+1)(2m+1)}{6}
%	%	\end{align}
%	We can write $s(l_2)$ as:
%	\begin{align*}
%		s(l_2)&= \sum_{i=1}^{m-2}{(i-\bltwo)^2}+(n-(m-2))(0-\bltwo)^2=\\
%		&= \sum_{i=1}^{m-2}{(i^2-2i\bltwo+\bltwo^2)}+(n-m+2)\bltwo^2=\\
%		&= \sum_{i=1}^{m-2}{i^2}-\sum_{i=1}^{m-2}{2i\bltwo}+ \sum_{i=1}^{m-2}{\bltwo^2}+(n-m+2)\bltwo^2=\\
%		&=\frac{(m-2)(m-2+1)(2(m-2)+1)}{6}-2\bltwo\frac{(m-2)(m-2+1)}{2} \\
%		& +(m-2)\bltwo^2 +(n-m+2)\bltwo^2= \\
%		&=\frac{1}{6}(m-2)(m-1)(2m-3)-(m-2)(m-1)\bltwo+\bltwo^2(m-2+n-m+2)=\\
%		&=\frac{1}{6}(m-2)(m-1)(2m-3)-\frac{(m-2)^2(m-1)^2}{2n}+n\bltwo^2=\\
%		&=\frac{1}{6}(m-2)(m-1)(2m-3)-\frac{(m-2)^2(m-1)^2}{2n}+n\frac{(m-2)^2(m-1)^2}{4n^2}=\\
%		&=(m-2)(m-1)\left(\frac{1}{6}(2m-3)-\frac{(m-2)(m-1)}{2n}+\frac{1}{2}\frac{(m-2)(m-1)}{2n}\right)=\\
%		&=(m-2)(m-1)\left(\frac{1}{6}(2m-3)-\frac{1}{2}\frac{(m-2)(m-1)}{2n}\right)
%	\end{align*} 
%	
%	Recall that our thesis is that $s(l_1)<s(l_2)$:
%	\begin{align*}
%		2 &< \frac{1}{6}(m-2)(m-1)(2m-3)-\frac{(m-2)^2(m-1)^2}{4n}\\
%		\frac{(m-2)^2(m-1)^2}{4n} &< \frac{1}{6}(m-2)(m-1)(2m-3)-2 \\
%		(m-2)^2(m-1)^2 &< \frac{2}{3}n(m-2)(m-1)(2m-3)-8n
%	\end{align*} 
%	When $m=4$ then $2^2 \cdot 3^2 < \frac{2}{3}n\cdot2 \cdot3\cdot5-8n$, thus $36<12n$ which is true for $n\geq4$.
%	When $m\geq5$ then $n\geq m-1$:
%	\begin{align*}
%		&(m-2)^2(m-1)^2 < \frac{2}{3}(m-2)(m-1)^2(2m-3)-8(m-1)\\
%		&0 < \frac{2}{3}(m-2)(m-1)^2(2m-3)-(m-2)^2(m-1)^2-8(m-1)\\
%		&(m-1)[(m-2)(m-1)\left(\frac{2}{3}(2m-3)-(m-2)\right)-8]>0\\
%		&(m-1)[(m-2)(m-1)\left(\frac{4m-6-3m+6}{3}\right)-8]>0\\
%		&(m-1)[(m-2)(m-1)\left(\frac{m}{3}\right)-8]>0\\
%	\end{align*}
%	The first coefficient $(m-1)$ is always positive, so consider only the second term:
%	\begin{align*}
%		&(m-2)(m-1)\left(\frac{m}{3}\right)-8>0\\
%		&\frac{(m-2)(m-1)m}{3}>8\\
%		&(m-2)(m-1)m>24\\
%	\end{align*}
%	Since $m\geq5$ then $(m-2)(m-1)m\geq 3\cdot4\cdot5=60>24$ which concludes the proof.
%\end{proof}
%
%\begin{proof} for $\sigma_{G}$. \\
%	Recall that 
%	\[\sigma_{G}(l)= \frac{\sum_{i=1}^{n}\sum_{j=1}^{n}|l_i-l_j|}{2 \cdot n \cdot \sum_{i=1}^{n} l_i}.\]	
%	Let us define $s(l)= \sum_{i=1}^{n}\sum_{j=1}^{n}|l_i-l_j|$, $t(l)=\sum_{i=1}^{n} l_i$ and $g(l)=s(l)/t(l)$. Consider the two vectors $l_1=(m-3, m-1, m-2, \dots, m-2)$ and $l_2=(m-2, m-3, \dots, 1, 0, \dots, 0)$. The thesis is now that $g(l_1) < g(l_2)$.
%	Note that $s(l)$ corresponds to the one computed for $\sigma_{mad}$ in \cref{proof:sigmamad} and recall that:
%	\begin{align*}
%		s(l_1)&=4n-4\\
%		s(l_2)&= (m - 2) (m - 1) \left(\frac{-2m + 3}{3} + n\right).
%	\end{align*}
%	Consider now $t(l)$. For $l_1$ the sum corresponds to the sum of the first two terms $m-3$, $m-1$ and $n-2$ times the term $m-2$, $t(l_1)=(m-3)+(m-1)+(n-2)(m-2)=n(m-2)$.
%	\begin{align*}
%		t(l_1)&=(m-3)+(m-1)+(n-2)(m-2)=\\
%		&=m-3+m-1-2m-4+n(m-2)=n(m-2)
%	\end{align*}
%	For $l_2$ it suffices to sum the terms from $1$ to $m-2$ because the $n-(m-2)$ terms left are $0$. Thus $t(l_2)=\sum_{i=1}^{n} l_2(i)=\sum_{i=1}^{m-2} l_2(i)=\frac{(m-2)(m-1)}{2}$.
%	Therefore we have:
%	\begin{align*}
%		g(l_1)&=\frac{4n-4}{n(m-2)};\\
%		g(l_2)&=(m - 2) (m - 1) \left(\frac{-2m + 3}{3} + n\right)\frac{2}{(m - 2) (m - 1)}=\\
%		&=\frac{-4m + 6}{3} + 2n.
%	\end{align*}
%	The thesis is now that $g(l_1) < g(l_2)$, so
%	\begin{align*}
%		\frac{4n-4}{n(m-2)}<&\frac{-4m + 6}{3} + 2n \\
%		3(4n-4)<&(-4m+6+6n)n(m-2)\\
%		12(n-1)<&2(-2m+3+3n)n(m-2)\\
%		6(n-1)<&n(-2m+3+3n)(m-2)\\
%	\end{align*}
%	For $m=4$ then:
%	\begin{align*}
%		&6(n-1)<n(-8+3+3n)(4-2)\\
%		&6(n-1)<2n(-8+3+3n)\\
%		&3(n-1)<-8n+3n+3n^2\\
%		&-5n+3n^2-3n+3>0\\
%		&3n^2-8n+3>0\\
%	\end{align*}
%	since $n\geq4$ then $3n^2-8n+3\geq 3 \cdot 16 - 8 \cdot 4+3 =43 > 0$.
%	For $m\geq5$ then $n\geq m-1$, so it suffices to prove it for $n=m-1$:
%	\begin{align*}
%		&6(m-1-1)<(m-1)(-2m+3+3m-3)(m-2)\\
%		&6(m-2)<(m-1)m(m-2)\\
%		&(m-1)m(m-2)-6(m-2)>0\\
%		&(m-2)((m-1)m-6)>0\\
%	\end{align*}
%	Since $m\geq5$ the first term is always positive, consider then $(m-1)m-6>0$ or $(m-1)m>6$ which is always true for $m\geq5$. Which concludes the proof.
%\end{proof}

%A \emph{spread measure} $\sigma: \alllosses → \R_{+}$ satisfies condition gamma iff  $\sigma (m-3,$ $m-1,m-2,...,$ $m-2)$ <$\sigma(m-2,$ $m-1,...1,$0, $\ 0)$.
%			(\lambda_{P}(y))$ that associates a spread value to every possible loss
%vector. We write On the other hand, $\lambda
%			^{P}(x)=(m-3,$ $m-1,m-2,...,$ $m-2)$ and $\lambda_{P}(y)=(m-2,$ $m-1,,...1,$
%			$0,$ $\ 0)$.

We write $\Sigma^{C_{m,n}} \subseteq \Sigma$ for the set of spread measures that satisfy condition $C_{m,n}$. 
\begin{theorem}
	For all $m\geq 4$, $n\geq \max\{4,m-1\}$, under $\Sigma^{C_{m,n}}$,
	\begin{itemize}
		\item [1)] $f_n^{w}$ fails \ac{PCC} when $w$ is the antiplurality score vector;
		\item [2)] the BK compromise  $f_n$ fails \ac{PCC}.
	\end{itemize}
\end{theorem}
\begin{proof}
	Given any $\sigma \in \Sigma^{C_{m,n}}$, let us exhibit some profile $P$ such that $f_n^{w} \cap \mustar = \emptyset$ and $f_n \cap \mustar = \emptyset$. To that aim, consider some $x,y\in A$ and some $P\in \linors^{N}$ with $r_{\prefi[1]}(x)=m-2$, $r_{\prefi[2]}(x)=m,$ $r_{\prefi}(x)=m-1$ $\forall i\in N \setminus \left\{ 1, 2\right\}$, and $r_{\prefi}(y)=m-i$ $\forall i\in \intvl{1,m-1}$, $r_{\prefi[n]}(y)=1$ $\forall i\in \intvl{m,n}$. Moreover, for each $z\in A \setminus \left\{ x,y\right\} $, let $r_{\prefi[1]}(z)=m$ for some $i\in N$. 
	
	Note that $f_n^{w}(P) = f_{n}(P) = \set{y}$. On the other hand, $\lambda^{P}(x)=(m-3, m-1,m-2,\dots,m-2)$ and $\lambda_{P}(y)=(m-2, m-3,\dots,1,0, \dots, 0)$. As $\sigma(\lambda_{P}(x)) < \sigma(\lambda_{P}(y))$ (because $\sigma \in \Sigma^{C_{m,n}}$), we see that $y\notin \mustar$.
\end{proof}

\section{Two-voters case}
In addition to \emph{fallback bargaining (FB)} \citep{Brams2001} (defined in \cref{sec:BKn3}), we consider three prominent solutions of the literature.

\emph{Pareto-and-Veto rules (PV)} \citep{Moulin1983, Abreu1991, Laslier2020} distribute a veto power of $v_1$ and $v_2$ alternatives to voters 1 and 2, respectively, with $v_1+v_2=m-1$. So, every voter $i=1,2$ (simultaneously) vetoes his worst $v_i$ alternatives. The \ac{SCR} picks all non-vetoed and Pareto optimal alternatives.

The \emph{Veto-Rank mechanism (VR)} is commonly used in the selection of arbitrators \citep{Clippel2014}. Given a list of $m$ (odd) alternatives (that are candidates to be arbitrators), each of the two voters (that are the two parties that must agree on an arbitrator) simultaneously vetoes his worst $\frac{m-1}{2}$ alternatives. The selected alternatives are the ones with the highest Borda score among the non-vetoed alternatives.

Again within the context of selecting arbitrators, \citet{Clippel2014} propose and analyse \emph{Shortlisting (SL)} where one of the two parties starts by vetoing her worst $\frac{m-1}{2}$ alternatives ($m$ being odd), and then the second party chooses her best alternative out of the remaining ones. As the outcome of the procedure depends on the party that starts, symmetry among players is ensured by defining the solution as the union of the two outcomes where one and the other party starts.


\begin{definition}
	Given any $m \geq 7$, a spread measure $\sigma \in \Sigma$ satisfies condition $D_m$ iff 
	$\sigma(\ceil{\frac{m}{2}}, \ceil{\frac{m}{2}} - 2) < \sigma(0, \ceil{\frac{m}{2}} - 1)$ and 
	$\sigma(\ceil{\frac{m}{2}} - 2, \ceil{\frac{m}{2}}) < \sigma(\ceil{\frac{m}{2}} - 1, 0)$.
\end{definition}

For $m=7$ the condition requires $\sigma(4, 2) < \sigma(0, 3)$ and $\sigma(2, 4) < \sigma(3, 0)$ which is reasonable in our context. When the value of $m$ is larger, the condition appears even more convincing. As $m$ grows, the distance between $0$ and $\ceil{\frac{m}{2}} - 1$ grows, while the distance between $\ceil{\frac{m}{2}}$ and $\ceil{\frac{m}{2}} - 2$ remains constant. Requiring, for example, the spread of $(15, 13)$ to be smaller than the spread of $(0, 14)$ is very reasonable.

We write $\Sigma^{D_{m}} \subseteq \Sigma$ for the set of spread measures that satisfy condition $D_{m}$. 

\begin{theorem} \label{th:2votPCC}
	Let $m \geq 7$. Under $\Sigma^{D_{m}}$, FB and PV fail \ac{PCC}. Furthermore, when $m$ is odd, VR and SL also fail \ac{PCC}.
\end{theorem}
\begin{proof}
	Take any $m \geq 7$ and any $\sigma \in \Sigma^{D_m}$. Define $\alpha = \ceil{\frac{m}{2}} - 1$ and $\beta = \ceil{\frac{m}{2}} - 2$. It follows from $\sigma \in \Sigma^{D_{m}}$, that $\sigma(\alpha + 1, \beta) < \sigma(0, \beta + 1)$ and $\sigma(\beta, \alpha + 1) < \sigma(\beta + 1, 0)$.
	For $m$ odd, note that $\alpha + \beta + 2 = m$ and consider the profile $P$ where voter $i_1$ has the preference $x \succ a_1 \succ … \succ a_\alpha \succ y \succ b_1 \succ … \succ b_\beta$ and voter $i_2$ has the preference $b_1 \succ … \succ b_\beta \succ y \succ x \succ a_1 \succ … \succ a_\alpha$. For $m$ even, note that $\alpha + \beta + 3= m$, and define the profile $P$ in the same way, except that a supplementary alternative $z$ is added at the bottom of both rankings.
	
	Note that $\sigma(\lambda_{P}(y)) = \sigma(\alpha + 1, \beta)$ and that $\sigma(\lambda_{P}(x)) = \sigma(0, \beta + 1)$. 
	Therefore, $\sigma(\lambda_{P}(y)) < \sigma(\lambda_{P}(x))$. As $y$ is not Pareto-dominated, an \ac{SCR} that uniquely picks $x$ at $P$ cannot be \ac{PCC}. In a similar vein, at the profile $P'$ which is obtained by the inversion of the preferences of $i_1$ and $i_2$ at $P$, an \ac{SCR} that is \ac{PCC} cannot pick $x$ uniquely.	
	
	The proof will be concluded by showing that FB, PV, and (when $m$ is odd) VR and SL all pick only $x$ at $P$ or at $P'$.
	
	We readily see that FB picks only $x$ at $P$ (and at $P'$) since $x$ is the first alternative which reaches the unanimous consent.
	For PV, let $v_{i_1} ≥ v_{i_2}$ (thus $v_{i_1} ≥ \ceil{\frac{m-1}{2}} ≥ \ceil{\frac{m-2}{2}} = \beta + 1$ and $v_{i_2} ≤ \floor{\frac{m - 1}{2}} = \ceil{\frac{m - 2}{2}} = \alpha$), and consider the profile $P$. Observe that the first voter vetoes at least $y$ and every $b_j$ ($1 ≤ j ≤ \beta$) while no voter vetoes $x$. As $x$ Pareto-dominates every $a_j$ ($1 ≤ j ≤ \alpha$), PV picks only $x$ at $P$. When $v_{i_2} ≥ v_{i_1}$, a similar reasoning yields that PV picks only $x$ at $P'$.
	
	Now let $m$ be odd.
	
	For VR, a reasoning similar to the one applied to PV yields $x$ as the unique choice at $P$: each voter vetoes her worst $\frac{m-1}{2}$ alternatives, thus $i_1$ vetoes $y$ and every $b_j$ ($1 ≤ j ≤ \beta$) and $i_2$ vetoes every $a_j$ ($1 ≤ j ≤ \alpha$). The alternative $x$ is the only non-vetoed alternative, so it is selected as the sole winner.
	
	Finally, SL also picks $x$, as it is the unique winner no matter which voter starts the veto phase. If $i_1$ starts, $y$ and every $b_j$ ($1 ≤ j ≤ \beta$) get vetoed, then $i_2$ chooses her best alternative out of the remaining ones which is $x$. If $i_2$ starts, every $a_j$ ($1 ≤ j ≤ \alpha$) get vetoed, then $i_1$ chooses her best alternative which is $x$. 
\end{proof}



\section{Concluding remarks}

We define an ex-post compromise as an outcome where individuals give up as equally as possible from their ideal points. With three or more individuals, several well known \acp{SCR} fail to pick ex-post compromises, under any reasonable meaning attributed to “giving up equally”. This failure is valid whether Pareto optimality is adopted or not. Our findings cover Condorcet extensions and scoring rules but also BK compromises, which impose a willingness to compromise without ensuring a compromised outcome. This failure prevails for social choice problems with two individuals: all well-known two-person \acp{SCR} of the literature, namely, fallback bargaining, Pareto and veto rules, short listing and veto rank, fail to pick ex-post compromises.

The exclusion of the equal-loss principle by almost all \acp{SCR} of the literature leads to ask whether the principle is uninteresting in a discrete social choice context. This seems to be the case for voting situations where the number of voters exceeds the number of candidates and usually every candidate is ranked last by at least one voter. In these cases, the main concern is about the support of alternatives rather than equality. On the other hand, two-person collective choice problems are typically interpreted as arbitration or bargaining situations where mutual consent is a critical element in reaching a solution. Thus, the equal-loss principle appears to be valid for two-person collective choice problems and our analysis raises the question of designing new discrete arbitration rules compatible with the equal-loss principle. 

We close by noting that viewing a compromise through the equal loss principle can be of particular interest in richer informational settings with cardinal individual preferences or a continuum of alternatives.
