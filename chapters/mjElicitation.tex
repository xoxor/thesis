%!TeX root= ../thesis.tex

\begin{abstract}
\ac{MJ} is a voting system where voters assign grades to candidates using an ordinal scale. The winner is the candidate with the highest majority-grade \textemdash which is the median of the grades received. This method has attracted increasing attention of french associations and political parties which have started to use \ac{MJ} for internal decisions or local elections. In particular LaPrimaire.org is a french association that uses \ac{MJ} to choose its candidate for the french presidential election. The vote is conducted in two rounds: in the first one the voters judge five candidates randomly picked; the five candidates with the highest medians pass at the second round as finalists and the voters are asked to judge them. Is the random selection of candidates a good elicitation technique? In this paper we explore the consequences of profile incompleteness and we question the elicitation of voters preferences.
\end{abstract}

\section{Introduction}
\label{sec:intro}
\ac{MJ} is a voting method proposed by \citet{Balinski2007,Balinski2011} to elect one out of $m$ candidates based on the judgments of $n$ voters. The latter express their preferences by assigning to each candidate one of the following adjectives: Excellent, Very good, Good, Average, Mediocre, Inadequate, To be rejected. Those adjectives represent a common language whose semantic is assumed to be a shared knowledge among the voters carrying thus an absolute meaning. For each candidate the median of the grades she received is computed, this is called \textit{majority-grade}. The candidate with the highest majority-grade is elected. Ties are broken by considering the majority-grade of first order: one vote associated with the majority-grade of each tied candidates is removed and their medians are recomputed. The candidate with the highest new median is elected. If there is still a tie the process is repeated until a unique winner is found. 

In the last few years \ac{MJ} has being adopted by a progressively larger number of french political parties including: Le Parti Pirate, Génération(s), LaPrimaire.org, France Insoumise and La République en Marche.
%https://www.lopinion.fr/edition/politique/en-marche-teste-elections-jugement-majoritaire-mode-scrutin-tres-201884
"Mieux Voter" \citep{MV} is a french association that promotes the use of \ac{MJ} as voting method whenever a collective choice has to be selected: public administration, associations, companies. On their website it is possible to find all the citizens lists \textendash party lists that are not affiliated to any national political party \textemdash that used \ac{MJ} to rank their candidates during the local elections of 2020. In two cases, Bordeaux et Annecy, the candidate selected using \ac{MJ} was then elected as a mayor. 

In particular, LaPrimaire.org \citep{LaPrimaire} is a french political initiative whose goal is to select an independent candidate for the french presidential election using \ac{MJ} as voting rule. The association Democratech implemented the platform for the first time in 2016 in view of the 2017 presidential elections. The number of voters who participated in the election was $10676$ during the first round (with $53383$ votes) and $32685$ during the second round (with $163425$ votes).

The procedure that they adopted consists of two rounds. In the first round each voter is asked to express her judgment, using \ac{MJ}, on five random candidates. At the end of this phase the five candidates with the highest medians are considered the finalists who qualify for the second round. In the second round each voter is asked to express her judgment, using \ac{MJ}, on all the five finalists. The candidate with the best median at the end of this phase is selected as representative for the presidential election.

In this paper we analyse this elicitation process of voters preferences. In particular, we investigate the consequences of randomness when asking the voters to judge candidates. We then search for more efficient techniques both in terms of communication cost \textemdash which can be quantified as number of questions per voter \textemdash and of fairness for candidates \textemdash which reflects the idea that a potential winner should not loose for lack of information.


\subsection{Related work}

One of the earliest uses of the median as an aggregator in voting theory can be identified in the \textit{middlemost} method proposed by \citet{Galton1907a,Galton1907b}. In particular, in situations where a group of people had to assess a damage, he suggested the median as the only method that does not suffer from over- or under-exaggerations.

We can consider the median grade as the highest level at which a candidate obtains the support of the majority of the voters. Starting for the highest grade $\delta$ we check if the majority of the voters assigned at least $\delta$ to some alternative. If this is not the case, we descend in the grading scale until such level $\delta^*$ is found. The grade $\delta^*$ is the median of grades associated to some alternative, and, since it is the first level we stopped at, it corresponds to the best possible median. This method was rediscovered several times and proposed under the name of Bucklin's rule \citep{Hoag1926}, Majoritarian Compromise \citep{Sertel1986,Sertel1999} and q-approval fallback bargaining \citep{Brams2001}. Moreover, when the number of grades is equal to two (approve, disapprove) then it is reduced to Approval Voting.

More recently \citet{Bassett1999} proposed the use of the median as voting rule for elections advocating for its robustness.
Several studies on the use of the median have been conducted. In particular, \citet{Bassett1994} and \citet{Gehrlein2003} study its manipulation. \citet{Barthelemy1981} survey mathematical problems and properties related to the notion of median in the context of cluster analysis and social choice theory. \cite{Nehring2022} analyze the median rule in judgment aggregation and they define a weighted median rule that is equivalent to \acs{MJ} except for the treatment of ties.

However, there is a significant concern that has never been analyzed when considering \ac{MJ}. Asking voters to provide a grade for each of the candidates can have a high cognitive and communicative cost. In situations where the set of alternatives is very large, voters may not be able to assign a significant and informed grades. \citet{Conitzer2005} studied the complexity of communication of some of the most common voting rules.
In these cases, elicitation strategies exist to retrieve the most relevant information. \citet{Konczak05} introduced the notion of possible and necessary winners. This paved the way for procedures that attempted to find necessary winners by asking voters the fewest questions possible \citep{Kalech2011}.
Considering scoring rules, \citet{Lu2011} suggested the use of minimax regret as a guide to the elicitation procedure. \citet{Bachrach2010} proposed a probabilistic approach. Several authors studied the complexity of determining when to stop the elicitation process for some of the most common voting rules \citep{Conitzer2002, Walsh2009}.
However, to the best of our knowledge, there are no works on preferences elicitation considering \ac{MJ}.

Very recently, \citet{Varloot2022} considered a version of \ac{MJ} under uncertainties in order to study its strategyproof properties. Their premise, however, is based on the fact that voters who are uncertain about the degree to assign to an alternative would instead assign to it a probability distribution. In other words, if a voter does not know whether to assign good or excellent to a certain alternative, then she may assign to it, for example, good with $\frac{1}{3}$ of the probability and excellent with $\frac{2}{3}$ of the probability. 
This approach requires the submission of even more information and is very far from our idea of incomplete knowledge.


\section{Notation}
\label{sec:complete}
Consider a finite set $N=\{i_1, \dots, i_n\}$ of voters (or judges) and a finite set $A=\{j_1, \dots, j_m\}$ of alternatives (or competitors). 
A \textit{common language} $\triangle = \{ \delta_1, \delta_2, \dots \}$ is a set of strictly ordered grades. It may, or may not, be finite and the notation $\delta_1 \geq \delta_2$ indicates that $\delta_1$ is a better or equivalent grade than $\delta_2$. A profile $P : A\times N \rightarrow \triangle$ is a $m$ by $n$ matrix of grades $P \in \triangle^{A \times N}$. Given any $N'\subseteq N$, the operator $\rho: \triangle^{N'} \rightarrow \triangle^{\card{N'}}$ defines an ordering function that given a vector of grades $P_j$ returns the vector ordered by decreasing grades.

Consider a set of alternatives $S\subseteq A$,
%where $|S|=s$ and $s \in \intvl{1,m}$ \textemdash the double brackets represent an interval in the integers. 
we denote by $P^S \in \triangle^{S \times N}$ a restriction of the profile $P$ to only the alternatives in $S$, $P^S \subseteq P$. Note that when $S=A$ then $P^S=P$.
%\commentOC{Could also write $\restr{P}{S × N}$, which leads to more generality, if restricting the users is also sometimes convenient.}

We define $f: \triangle^{N} \rightarrow \triangle$ a function that assigns to any vector of grades a final grade. Given any $S\subseteq A$, a grading function $f^S: \triangle^{S \times N} \rightarrow \triangle^S$ returns a vector of final grades by applying $f$ to every alternative in $S$.
% the \emph{middlemost} aggregation function $f$, for each vector of grades $r_i= (r_1 , \dots, r_n )$ associated to the alternative $i \in \intvl{1,m}$, returns: 
%\begin{align}
%	f(r_i) &= r_{(n+1)/2} \text{ when n is odd,} \\
%	r_{n/2} \geq f(r_i) &\geq r_{(n+2)/2} \text{ otherwise.}
%\end{align}

The \emph{majority-grade}, $\fmaj$, is the function that associates to a vector of grades $\emptyset \neq q \in \triangle^{N'}, N' \subseteq N$ its median grade value: $\fmaj(q) = \rho(q)_{\floor{\frac{\card{q}}{2}} + 1}$. Note that in case $\card{q}$ is even two medians could be used, but, as in \citet{Balinski2011} definition, the lower grade is picked. Given any $S\subseteq A$, by applying $\fmaj$ to all vectors of grades associated to the alternatives in $S$ we obtain the corresponding grading function $\fmaj[S]$. Formally, $\fmaj[S](P^S)_j = \fmaj(P^S_j)$. The $j$-\emph{th} element of the resulting vector is the median of the ordered vector of grades associated to the $j$-\emph{th} alternative. 
%Because $f^S_{maj}(P^S)_i$ depends only on $P^S_i$ we write $f^S_{maj}(P^S_i)$. \commentOC{I am not sure I follow. You already have a notation for this, namely, $\fmaj(P^S_i)$, isn’t it?}
Moreover, when we consider the complete profile (when $S=A$) we will write $\fmaj(P_j)$ instead of $\fmaj[A](P^A_j)$.
\commentOC{I doubt that the general $f$ is actually useful, you only seem to use $f$ maj.}
%i.e. it corresponds to the lower middlemost.

Given any $S\subseteq A$, the winner function $\Fmaj[S]:\triangle^{S \times N} \rightarrow A$ %$F^S_{maj}:\triangle^{S \times N} \rightarrow 2^A \setminus \emptyset$
is a function that selects the alternative with the highest median grade as winner. We can define it as $\Fmaj[S](P^S) = \argmax_{j\in S}\rho(P^S_j)_{\floor{\frac{n}{2}}+ 1}$ assuming it is a singleton. \commentBN{I think it makes more sense to define it with $\fmaj$: $\Fmaj[S](P^S) = \argmax_{j\in S}\fmaj(P^S_j)$} For brevity, we will write $\Fmaj$ when considering $S=A$. Consider the case when it is not a singleton, this means that two or more alternatives are associated with the same highest median grade $h=\max_{j\in S}\rho(P^S_j)_{\floor{\frac{n}{2}} + 1}$ \commentBN{$h=\max_{j\in S}\fmaj(P^S_j)$}. In this case ties are broken by removing one $h$ grade from the vectors of grades of each tied alternative, recomputing the new median grade and repeating the process until one unique winner is found or there are no more grades to remove. When $n$ is odd, this is equivalent to take the next element after the median, i.e. the one at index $(\floor{\frac{n}{2}} + 1) +1$. If there is still a tie we then look at the previous element before the median, i.e. the one at index $(\floor{\frac{n}{2}} + 1) -1$, and keep alternating until the tie is broken or there are no more elements in the vector. When $n$ is even the element before the median, i.e. the one at index $\floor{\frac{n}{2}}$, is taken first and, if there is still a tie, then the element after the median is considered, i.e. the one at index $\floor{\frac{n}{2}} + 2$, and so on. If after applying the mechanism there are still ties we break them using an arbitrary ordering defined on all alternatives, e.g. lexicographical order.

Similarly to the winner function, given any $x \in \intvl{1,m}$, we can define a more general \emph{selection function} $F^S_x:\triangle^{S\times N} \rightarrow 2^A \setminus \emptyset$ that selects exactly the $x$ alternatives with the $x$ highest median grades.
\commentOC{$F^S_x(P^S) = f^S_\mathit{maj}(P^S) \cup f^{S'}_\mathit{maj}(P^{S'}) …$.} \commentBN{Did you mean capital F? $F^S_x(P^S) = \Fmaj[S](P^S) \cup \Fmaj[S'](P^{S'}) \cup \dots \cup \Fmaj[S^{k-1}](P^{S^{k-1}})$ where $S'= S \setminus \Fmaj[S](P^{S})$, $S''= S \setminus \Fmaj[S](P^S) \setminus \Fmaj[S'](P^{S'})$ etc.}


\subsection{Incomplete knowledge}
In order to analyze the elicitation procedure used by LaPrimaire.org, we need to adapt the notation just described to incomplete profiles. 
\commentOC{Defining the right, full notations from the start would be more gentle for the reader.} \commentBN{To discuss, I think at the end we decided to keep it like this?} Let $\Pbar$ be our knowledge about the profile $P$.
The voters have full knowledge of their own judgments but we ignore them; our goal is to elicit them by questioning the voters starting from zero knowledge.
We introduce an additional grade $\dbar$, and, given a language $\Delta$, $\dbar< \delta, \forall \delta \in \Delta$.
%\commentBN{I think we should avoid to say this but rather add in $\bar{F}$ that the $\dbar$ are excluded.}
The common language in the incomplete knowledge setting is then $\overline{\triangle}=\triangle \cup \dbar$. Voters cannot use this grade to express their judgment over an alternative and it does not count in the computation of the median grade as we will explain formally. We refer to the grades in $\triangle$, the ones used by voters, as "defined" grades.

The starting knowledge is represented by a matrix $m\times n$ of $\dbar$ grades. Given $k \in \N$, we define with $K_i \subseteq A$ a set of $k$ alternatives that we ask the voter $i\in N$ to judge. 
After having asked every voter in $N$ to judge $k$ candidates, we obtain an \emph{incomplete profile} $\Pbar\in \overline{\triangle}^{A \times N}$, that is a matrix $m \times n$ of grades of which $kn$ are "defined".
Note that when $k=n$ the resulting profile $\Pbar$ corresponds to the complete profile $P$. Let $C(\Pbar) = \{P' \in \triangle^{m \times n} \suchthat \Pbar \subseteq P'\}$ be the set of all completions of $\Pbar$ obtained by substituting all $\dbar$ grades with "defined" ones, note that $P \in C(\Pbar)$.
\commentOC{Technically that’s not correct as $P$bar may contain some “undefined”, in which case $P$ can’t be a superset of it. (Can be left as is for now.) Also, I suppose that $P$ should keep the identities of the alternatives and voters.}\commentBN{How can I write something like $\restr{\Pbar}{\triangle}\subseteq P'$ meaning the restriction of only defined grades?}
 
If $K_i=K_l, \forall i,l\in N$, i.e. if we ask all voters to judge the same $k$ alternatives, then we have complete knowledge restricted to this set of candidates. We denote with $P^{K_i}$ the restriction of the complete profile $P$ to only the alternatives in $K_i$.
\commentOC{I wonder if this notation will be useful.}

Let $g:\overline{\triangle}^N\rightarrow \bigcup_{N' \subseteq N}\triangle^{N'}$ be a function that given an incomplete vector of grades $q \in \overline{\triangle}^N$, thus $q \subseteq N × \bar{\triangle}$, returns the vector composed only of the "defined" grades $g(q) = \restr{q}{N × \triangle}$.

%The operator $\overline{\rho}$ defines a restricting ordering function that given $\overline{P_i}$, an incomplete vector of $n$ grades, returns the correspondent complete vector restricted to its $x$ "defined" grades decreasingly ordered: $\overline{\rho}(\overline{P_i})=\rho(d(\overline{P_i}))$. \commentBN{Not sure this is necessary.}

Given any $S \subseteq A$, the \emph{majority-grade} for incomplete profile $\fmajbar[S]: (\bigcup_{x \in \intvl{1,n}}\triangle^{x})^S \rightarrow \triangle^S$ corresponds to $\fmaj[S]$ that only considers the "defined" grades in the computation of the median. Indeed, consider an incomplete profile $\overline{P^S}$ and denote by $P'_j=g(\Pbar^S_j)$, then $\fmaj(P'_j) = \rho(P'_j)_{\floor{\frac{\card{P'_j}}{2}} + 1}$, $\forall i \in S$.
\commentOC{I suppose you mean to apply $\rho$ on $P'_j$. Also, your definition makes sense more generally for any $P'_j$ of the right type, not just when $P'_j = g(…)$. In fact, this $f$ is already defined!}\commentBN{Can I say $\fmajbar[S](\overline{P^S_j})=\fmaj[S](P'_j) = \rho(P'_j)_{\floor{\frac{\card{P'_j}}{2}} + 1}$}
In a similar fashion, we can define $\Fmajbar[S](\Pbar)=\argmax_{j\in S}\fmajbar[S](\Pbar^S_j)$ and, given a $x\in \intvl{1,m}$, the selection function $\overline{F}^S_x(\Pbar^S) = \Fmajbar[S](\Pbar^S) \cup \Fmajbar[S'](\Pbar^{S'}) \cup \dots \cup \Fmajbar[S^{x-1}](\Pbar^{S^{x-1}})$ where $S'= S \setminus \Fmajbar[S](\Pbar^{S})$, $S''= S \setminus \Fmajbar[S](\Pbar^S) \setminus \Fmajbar[S'](\Pbar^{S'})$ etc.

To summarize the elicitation process we want to investigate, starting with zero knowledge, each voter is asked to judge $k$ candidates. Given the partial information at our disposal, we are able to define the "known" median grade for each alternative. We can now use the \emph{selection function} $\overline{F}^S_k$ to select the $k$ alternatives with the highest "known" median grades. We will call this set of alternatives $K=\overline{F}^S_k\subseteq A$. These $k$ alternatives will be presented to all voters, who must provide a grade for each of them, thus obtaining a restriction of the complete profile to this subset of $k$ alternatives. From here, the functions for the complete profiles can be used selecting a winning alternative.

%I'm not sure the following is relevant
%
%Given the set $\tilde{K}=F^S_k(g(\Pbar^S_j))$ of the best $k$ alternatives, every voter is then asked to judge all the candidates in $\tilde{K}$. 
%\commentOC{$i$ is not defined; and there may be a type incompatibility between the result of $g$ and the domain of $F^S_k$.}
%
%This process results in a restriction $P^{\tilde{K}}$ of the complete profile $P$. It is important to mention that when we ask the voters to judge an alternative $i\in \tilde{K}$ we assume that they report their preference as they would have stated it when asked about $P$. In other words, $P^{\tilde{K}}_{i} = P_j$ for any $i \in \tilde{K}$.
%\commentOC{The formal part of this does not look like your informal hypothesis.}
%
%Please note that $P^{\tilde{K}}$ is a complete matrix of $kn$ grades and that we fall back to the complete profile case, thus, we apply the \emph{majority-grade}, $\fmaj[\tilde{K}]$, function to $P^{\tilde{K}}$ to determine the median grades and then the winner function $\Fmaj[\tilde{K}]$ to select the winner. 
%For simplicity we denote by $\overline{W}_{\overline{P^k}} \subseteq A$ the results of this process.

\begin{remark}
	Because we are interested into investigating \acs{MJ}, we are going to use an alphabet with the same size of the one proposed by \citet{Balinski2011} which is composed of the following adjectives: To be Rejected, Inadequate, Mediocre, Average, Good, Very Good, Excellent. For brevity we are gonna rename those adjectives respectively from $\delta_1$, corresponding to To be Rejected, to $\delta_7$, corresponding to Excellent. Therefore, $\triangle=\{\delta_1,\delta_2, \delta_3,\delta_4,\delta_5,\delta_6,\delta_7\}$ 
\end{remark}

\section{Reasoning on incompleteness}
Let us now consider the effects of incomplete knowledge on the selection of a winner. In particular, we want to prove that if we consider an incomplete profile and take the $k$ alternatives with the highest median grade, with any $k$ being between $1$ and $m-1$, it is possible to miss the winner of one of its completion. 
This is important because in the elicitation process implemented by LaPrimaire.org, only the full grade vectors of the $k$ alternatives with the highest median grade are considered. Clearly, if the winning alternative in the complete profile is in this set $K \subset A$, then she will also be the winner of the incomplete profile. This is because the voters will be asked to provide a grade for all those $k$ alternatives, providing thus a restriction of the complete profile to only the alternatives in $K$, i.e. $P^K$. If a candidate is a winner for a complete profile, then she is also a winner for any of its restrictions that include her.
Note that this is not true in case of multiple winners where ties that cannot be broken by tie-breaking procedures and for which arbitrary ordering is, therefore, necessary. In what follows we assume the absence of such ties.
We want to show that it is possible for the winning alternative of the complete profile not to be included in this subset $K$ of alternatives.

	\begin{theorem}
		\label{th:notinK}
		Given a set $A$ of alternatives $m\geq 2$, a set of voters $N$ and a value $k\in \intvl{1,m-1}$, there exist a complete profile $P$ and an incomplete profile $\Pbar$ such that $P \in C(\Pbar)$ and $\Fmaj(P) \nsubseteq \overline{F}_k(\Pbar)$.
	\end{theorem}
	\begin{proof}
		Consider the following complete profile $P$
		\begin{center}
			$
			\begin{array}{ccccc}
				& i_1 & i_2 & \dots & i_n \\
				j_1 &	\delta_7 & \delta_7 & \dots & \delta_7 \\
				j_2 &	\delta_6 & \delta_6 & \dots & \delta_6 \\
				. &	\delta_6 & \delta_6 & \dots & \delta_6 \\
				j_m &	\delta_6 & \delta_6 & \dots & \delta_6 \\
			\end{array} \quad,
			$
		\end{center}
		where all voters judge all alternatives $\delta_6$ except for the alternative $j_1$ which is judged $\delta_7$ by everyone.
		The median grade of the alternative $j_1$ is $\fmaj(P_{j_1})=\delta_7$ and the one of all the other alternatives is $\fmaj(P_x)=\delta_6, \forall x \in A \setminus \{j_1\}$. Thus, the winner in the profile $P$ is $\Fmaj(P)=\{j_1\}$.
		Consider now the following incomplete profile $\Pbar$:
		\begin{center}
			$
			\begin{array}{ccccc}
				& i_1 & i_2 & \dots & i_n \\
				j_1 & \dbar & \dbar & \dots & \dbar \\
				j_2 &	\delta_6 & \delta_6 & \dots & \delta_6 \\
				. &	\delta_6 & \delta_6 & \dots & \delta_6 \\
				j_m &	\delta_6 & \delta_6 & \dots & \delta_6 \\
			\end{array} \quad.
			$
		\end{center}
		The median grade of $j_1$ under the profile $\Pbar$ is $\fmaj(\Pbar_{j_1})=\dbar$ and the one of all the other alternatives is $\fmaj(\Pbar_x)=\delta_6, \forall x \in A \setminus \{j_1\}$. Because $\dbar < \delta_6$, $\overline{F}_k(\Pbar)$ will be any subset of $k$ elements of $\{j_2,j_3,\dots,j_m\}$, for any $k\in \intvl{1,m-1}$. Since all those alternatives have the same grade vectors, some orderings can be used to define the members of $\overline{F}_k(\Pbar)$.	
		Thus, $j_1 \notin \overline{F}_k(\Pbar)$, and $\Fmaj(P) \subsetneq \overline{F}_k(\Pbar)$, for any $k\in \intvl{1,m-1}$.
	\end{proof}

	From \Cref{th:notinK}, considering $k=1$ and recalling that $\overline{F}_{k=1}(\Pbar) = \Fmajbar(\Pbar)$ we can conclude that there exist an incomplete profile and one of its completion that do not have the same winner.
	\begin{remark}
		Given a set of alternatives $A$ and a set of voters $N$, there exist a complete profile $P$ and an incomplete profile $\Pbar$ such that $P \in C(\Pbar)$ and $\Fmaj(P) \neq \Fmajbar(\Pbar)$.
	\end{remark}

	
	We have shown that it is possible to find a complete profile $P$ whose winner is not in the set $K$ of alternatives with the highest medians for an incomplete profile $\Pbar$, with $P \in C(\Pbar)$.
	If we look at the procedure used by LaPrimaire.org, however, the situation is slightly more complex. We are not considering just any incomplete profile, but a $k$ value is set from the beginning and the incomplete profile is formed by asking each voter to rate $k$ random chosen candidates. They set $k=5$.
	The $k$ alternatives with the highest medians on this incomplete profile form $K$.
	
	Note that, the example profile $\Pbar$ considered in the proof of \Cref{th:notinK} could be the result of a random process of questioning the voters about $k=m-1$ alternatives, and they never got the chance to grade the alternative $j_1$.
	
	In what follow, we denote with $\Pbar^k$ an incomplete profile where every voter judges $k\in \intvl{1,m-1}$ alternatives. If we consider the matrix $m \times n$ of grades, then the columns, i.e. the vectors of grades expressed by each voter, are composed of only $k$ "defined" grades.
	
	\begin{theorem}
		\label{th:uncompleteK}
		Given a set $A$ of alternatives $m\geq 2$, a set of voters $N$ and a value $k\in \intvl{1,m-1}$, there exist a complete profile $P$ and an incomplete profile $\Pbar^k$ such that $P \in C(\Pbar^k)$ and $\Fmaj(P) \nsubseteq \overline{F}_k(\Pbar^k)$.
	\end{theorem}
	\begin{proof}
		Consider the complete profile $P$ defined in the proof of \Cref{th:notinK}, we will show how to construct an incomplete profile for any value of $k\in \intvl{1,m-1}$ such that the statement is true. Let us call $K=\overline{F}_k(\Pbar^k)$.
		Note that we can select any complete profile where there is one alternative $j$ graded the highest by everyone, and all the other alternatives are considered worst by everyone
		
		When $k=m-1$, the proof follows from the proof of \Cref{th:notinK}. The set of the $m-1$ alternatives with the highest medians is $K=\{j_2,j_3,\dots,j_m\}$. Thus, $\Fmaj(P)=j_1 \notin K$.
		
		For any other $k<m-1$ we can follow the same reasoning by building $\Pbar^k$ making sure that we never ask anyone the grade of $j_1$. 
		The grade vector of $j_1$ is $\Pbar^k_{j_1}=(\dbar, \dots, \dbar)$ and $\fmajbar(\Pbar^k_{j_1})=\dbar$.
		Two situations are now possible: $(1)$ either there exist $k$ alternatives $j',\dots j^k\in A$ for which is already the case that their median grade is defined (i.e. $\fmajbar(\Pbar^k_{j'})>\dbar$); or $(2)$ the majority grade of all alternatives is $\dbar$. 
		In fact, in the first case, $(1)$, each voter could grade the same $k$ alternatives, so they would have a complete grade vector and their median grade would be "defined". Because the median of all the rest of alternatives is $\dbar < \delta, \forall \delta \in \Delta$, those $k$ alternatives would be selected as set $K$.
		In the second case, $(2)$, each voter could judge a set of $k$ different alternatives from $A\setminus j_1$. Note, however, that in any case there are at least $k$ alternatives with at least one "defined" grade. When we apply the tie-breaking procedure, we will arrive at a point where the median grade of at least $k$ alternatives is "defined". Thus $\fmajbar(\Pbar^k_{j_1})=\dbar$ will be lower than at least $k$ others and it will not be selected in $K$.
	\end{proof}	
	
	From \Cref{th:uncompleteK}, considering $k=1$ we have that:
	\begin{remark}
		Given a set $A$ of alternatives $m\geq 2$, a set of voters $N$ and a value $k\in \intvl{1,m-1}$, there exist a complete profile $P$ and an incomplete profile $\Pbar^k$ such that $P \in C(\Pbar^k)$ and $\Fmaj(P) \neq \Fmajbar(\Pbar^k)$.
	\end{remark}

	In the proofs of \Cref{th:notinK,th:uncompleteK} we showed the existence of an incomplete profile whose $k \in \intvl{1,m-1}$ best alternatives did not include the winner of one of its completions. To do so, we assumed that no questions were asked about an alternative $j$ winner in the complete profile $P$. Although the theoretical result remains, how likely is this to happen in practice?
	
	\begin{proposition}
		\label{pr:probabilityJ}
		Given a set $A$ of $m$ alternatives, a set $N$ of $n$ voters, a value $k\in\intvl{1,m-1}$ and considering an elicitation strategy in which each voter is asked to judge $k$ alternatives, the probability of never asking any voter about an alternative $j\in A$ is $(1-\frac{k}{m})^n$.
	\end{proposition}
	\begin{proof}
		To prove this let us first consider $e_i$ the event of asking a voter $i\in N$ to grade the alternative $j$ in $k$ questions, and let us compute the probability $\mathcal{P}$ of this event to happen.
		There are $\binom{m-1}{k-1}$ ways to select $k$ alternatives among $m$ that include the alternative $j$. This is because once we select the alternative $j$ we can still pick $k-1$ alternatives to ask the voter among the remaining $m-1$.
		Moreover, there are $\binom{m}{k}$ ways to select $k$ alternatives among $m$ with no constraints. Thus, the probability of asking a voter to grade the alternative $j$ in $k$ questions is:
		\[\mathcal{P}(e_i)= \frac{\binom{m-1}{k-1}}{\binom{m}{k}}=\frac{\frac{(m-1)!}{(k-1)!(m-1-k+1)!}}{\frac{m!}{k!(m-k)!}}=\frac{(m-1)!}{(k-1)!(m-k)!}\cdot\frac{k(k-1)!(m-k)!}{m(m-1)!}=\frac{k}{m}.\]
		The probability that one voter is never questioned about an alternative is then:
		\[\mathcal{P}(\overline{e_i})=1-\mathcal{P}(e_i)=1-\frac{k}{m}.\]
		Because questionings different voters are independent events, we can express the probability that no voter is asked to grade an alternative $j$ as the product of the individual probabilities. Denoting this event with $e_j$ we have that:
		\[\mathcal{P}(e_j)=\mathcal{P}(e_i)^n=\left(1-\frac{k}{m}\right)^n.\]
	\end{proof}

	\begin{remark}
		\label{rm:sizeGV}
		After asking each of the $n$ voters to grade $k\in \intvl{1,m-1}$ of the $m$ alternatives, the average size of the grade vectors is $q = n \cdot \frac{k}{m}$.
	\end{remark}
	This observation comes from the proof of \Cref{pr:probabilityJ}. Given an alternative $j\in A$ and a voter $i\in N$ the probability that $i$ is asked about $j$, thus that $\Pbar_{j}(i)$ is defined, is $\frac{k}{m}$. The probability that the whole vector $\Pbar_{j}$ is composed of defined grades is then $n \cdot \frac{k}{m}$. This gives us an approximation on the number of elements of the grade vector, because for each of the $n$ elements, we have $\frac{k}{m}$ probability that the element is defined.
	
	The value found in \Cref{pr:probabilityJ} is very low to occur in real examples, if, for example, we consider $k=3$, $n=m=10$ the probability that none is asked to grade the winner of the complete profile is $0.7^{10}$ (which approximated is $0.0282\%$).
	However, this is also very restrictive. For an alternative $j$, winner of the complete profile, not to be the winner of the incomplete profile it suffices for her median to be smaller than the one of other $k$ alternatives. 
	We do not need the vector of the alternative considered to be empty, just to be misrepresented enough to have a median lower than $k$ others.
	
	\begin{example} \normalfont
		Consider the following profile $P$:
		\begin{center}
			$
			\begin{array}{ccccccc}
					& i_1 & \dots & i_{\floor{\frac{n}{2}} + 1} & i_{\floor{\frac{n}{2}} + 2} & \dots & i_n \\
				j_1 & \delta_7 & \dots &\delta_7 & \delta_5 & \dots & \delta_5 \\
				j_2 & \delta_6 & \dots &\delta_6 & \delta_6 & \dots & \delta_6 \\
				. & \delta_6 & \dots &\delta_6 & \delta_6 & \dots & \delta_6 \\
				j_m & \delta_6 & \dots &\delta_6 & \delta_6 & \dots & \delta_6 \\
			\end{array} \quad.
			$
		\end{center}	
		Exactly $\floor{\frac{n}{2}} + 1$ voters grade the alternative $j_1$ with the highest grade $\delta_7$ and the rest of the voters grade her $\delta_5$. All voters grade any other alternative $\delta_6$.
		The median grade of $j_1$ is $\fmaj(P_{j_1})=\delta_7$ and the one of all the other alternatives is $\fmaj(P_x)=\delta_6, \forall x \in A \setminus \{j_1\}$. Thus, $j_1$ is the winner of the profile $P$.
		For $j_1$ not to be the winner of any $\Pbar$ such that $P \in C(\Pbar)$, it must be that $\fmajbar(j_1)=\delta_5$. This happens when the incomplete grade vector of $j_1$ has a number of $\delta_5$ grades more or equal to $\delta_7$ grades. 
		Let us denote with $q=|\Pbar_{j_1}|$ the size of the incomplete grade vector of $j_1$.
		Assume, for the sake of simplicity, that $n$ and $q$ are both even, although this reasoning can easily be adapted in case they are odd.
		An incomplete grade vector whose median is $\delta_5$, could be formed by $q/2$ $\delta_7$ grades and $q/2$ $\delta_5$ grades. To compute the probability of this vector to be formed, we must consider that there are $\binom{\frac{n}{2}+1}{ \frac{q}{2}}$ ways of taking $q/2$ of the $\frac{n}{2}+1$ $\delta_7$ grades of the complete vector. Moreover, there are $\binom{\frac{n}{2}-1}{ \frac{q}{2}}$ ways of taking $q/2$ of the $\frac{n}{2}-1$ $\delta_5$ grades. If we consider no restrictions there are $\binom{n}{q}$ ways of taking a vector of $q$ grades out of a vector of $n$ elements.
		However, this is not the only vector whose median is $\delta_5$. In fact, we could have $q/2-1$ $\delta_7$ grades and $q/2+1$ $\delta_5$ grades. If we iterate this reasoning on all the possible division of $q$ we have that:
	
		\[ \mathcal{P}= \sum_{i=0}^{q/2} \frac{\binom{\frac{n}{2}+1}{ \frac{q}{2}-i}\cdot\binom{\frac{n}{2}-1}{\frac{q}{2}+i}}{\binom{n}{q}} \]
		
		Because we know from \Cref{rm:sizeGV} that the average size of any grade vector is $q=n\cdot\frac{k}{m}$, we experimentally tested this probability with different values of $n,m$ and $k$. Except when $k$ is very close to $m$, and then we have almost the whole vector, we have that this probability is $\mathcal{P}\approx \frac{1}{2}$.
	\end{example}

	Again, the profile considered here is rather peculiar and not of practical use. In the next section we investigate experimentally different profile distributions.


\section{Experimental results}






	