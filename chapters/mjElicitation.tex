%!TeX root= ../thesis.tex

\begin{abstract}
\ac{MJ} is a voting system where voters assign grades to candidates using an ordinal scale. The winner is the candidate with the highest majority-grade \textemdash which is the median of the grades received. This method has attracted increasing attention of french associations and political parties which have started to use \ac{MJ} for internal decisions or local elections. In particular LaPrimaire.org is a french association that uses \ac{MJ} to choose its candidate for the french presidential election. The vote is conducted in two rounds: in the first one the voters judge five candidates randomly picked; the five candidates with the highest medians pass at the second round as finalists and the voters are asked to judge them. Is the random selection of candidates a good elicitation technique? In this paper we explore the consequences of profile incompleteness and we question the elicitation of voters preferences.
\end{abstract}

\section{Introduction}
\label{sec:intro}
\ac{MJ} is a voting method proposed by \citet{Balinski2007,Balinski2011} to elect one out of $m$ candidates based on the judgments of $n$ voters. The latter express their preferences by assigning to each candidate one of the following adjectives: Excellent, Very good, Good, Average, Mediocre, Inadequate, To be rejected. Those adjectives represent a common language whose semantic is assumed to be a shared knowledge among the voters carrying thus an absolute meaning. For each candidate the median of the grades she received is computed, this is called \textit{majority-grade}. The candidate with the highest majority-grade is elected. Ties are broken by considering the majority-grade of first order: one vote associated with the majority-grade of each tied candidates is removed and their medians are recomputed. The candidate with the highest new median is elected. If there is still a tie the process is repeated until a unique winner is found. 

In the last few years \ac{MJ} has being adopted by a progressively larger number of french political parties including: Le Parti Pirate, Génération(s), LaPrimaire.org, France Insoumise and La République en Marche.
%https://www.lopinion.fr/edition/politique/en-marche-teste-elections-jugement-majoritaire-mode-scrutin-tres-201884
"Mieux Voter" \citep{MV} is a french association that promotes the use of \ac{MJ} as voting method whenever a collective choice has to be selected: public administration, associations, companies. On their website it is possible to find all the citizens lists \textendash party lists that are not affiliated to any national political party \textemdash that used \ac{MJ} to rank their candidates during the local elections of 2020. In two cases, Bordeaux et Annecy, the candidate selected using \ac{MJ} was then elected as a mayor. 

In particular, LaPrimaire.org \citep{LaPrimaire} is a french political initiative whose goal is to select an independent candidate for the french presidential election using \ac{MJ} as voting rule. The association Democratech implemented the platform for the first time in 2016 in view of the 2017 presidential elections. The number of voters who participated in the election was $10676$ during the first round (with $53383$ votes) and $32685$ during the second round (with $163425$ votes).

The procedure that they adopted consists of two rounds. In the first round each voter is asked to express her judgment, using \ac{MJ}, on five random candidates. At the end of this phase the five candidates with the highest medians are considered the finalists who qualify for the second round. In the second round each voter is asked to express her judgment, using \ac{MJ}, on all the five finalists. The candidate with the best median at the end of this phase is selected as representative for the presidential election.

In this paper we analyse this elicitation process of voters preferences. In particular, we investigate the consequences of randomness when asking the voters to judge candidates. We then search for more efficient techniques both in terms of communication cost \textemdash which can be quantified as number of questions per voter \textemdash and of fairness for candidates \textemdash which reflects the idea that a potential winner should not loose for lack of information.


\subsection{Related work}

One of the earliest uses of the median as an aggregator in voting theory can be identified in the \textit{middlemost} method proposed by \citet{Galton1907a,Galton1907b}. In particular, in situations where a group of people had to assess a damage, he suggested the median as the only method that does not suffer from over- or under-exaggerations.

We can consider the median grade as the highest level at which a candidate obtains the support of the majority of the voters. Starting for the highest grade $\delta$ we check if the majority of the voters assigned at least $\delta$ to some alternative. If this is not the case, we descend in the grading scale until such level $\delta^*$ is found. The grade $\delta^*$ is the median of grades associated to some alternative, and, since it is the first level we stopped at, it corresponds to the best possible median. This method was rediscovered several times and proposed under the name of Bucklin's rule \citep{Hoag1926}, Majoritarian Compromise \citep{Sertel1986,Sertel1999} and q-approval fallback bargaining \citep{Brams2001}. Moreover, when the number of grades is equal to two (approve, disapprove) then it is reduced to Approval Voting.

More recently \citet{Bassett1999} proposed the use of the median as voting rule for elections advocating for its robustness.
Several studies on the use of the median have been conducted. In particular, \citet{Bassett1994} and \citet{Gehrlein2003} study its manipulation. \citet{Barthelemy1981} survey mathematical problems and properties related to the notion of median in the context of cluster analysis and social choice theory. \cite{Nehring2022} analyze the median rule in judgment aggregation and they define a weighted median rule that is equivalent to \acs{MJ} except for the treatment of ties.

However, there is a significant concern that has never been analyzed when considering \ac{MJ}. Asking voters to provide a grade for each of the candidates can have a high cognitive and communicative cost. In situations where the set of alternatives is very large, voters may not be able to assign a significant and informed grades. \citet{Conitzer2005} studied the complexity of communication of some of the most common voting rules.
In these cases, elicitation strategies exist to retrieve the most relevant information. \citet{Konczak05} introduced the notion of possible and necessary winners. This paved the way for procedures that attempted to find necessary winners by asking voters the fewest questions possible \citep{Kalech2011}.
Considering scoring rules, \citet{Lu2011} suggested the use of minimax regret as a guide to the elicitation procedure. \citet{Bachrach2010} proposed a probabilistic approach. Several authors studied the complexity of determining when to stop the elicitation process for some of the most common voting rules \citep{Conitzer2002, Walsh2009}.
However, to the best of our knowledge, there are no works on preferences elicitation considering \ac{MJ}.

Very recently, \citet{Varloot2022} considered a version of \ac{MJ} under uncertainties in order to study its strategyproof properties. Their premise, however, is based on the fact that voters who are uncertain about the degree to assign to an alternative would instead assign to it a probability distribution. In other words, if a voter does not know whether to assign good or excellent to a certain alternative, then she may assign to it, for example, good with $\frac{1}{3}$ of the probability and excellent with $\frac{2}{3}$ of the probability. 
This approach requires the submission of even more information and is very far from our idea of incomplete knowledge.


\section{Notation}
\label{sec:complete}
Consider a finite set $N$ of voters (or judges) with $\#N=n$ and a finite set $A$ of alternatives (or competitors) with $\#A=m$. 
A \textit{common language} $\triangle = \{ \delta_1, \delta_2, \dots \}$ is a set of strictly ordered grades. It may, or may not, be finite and the notation $\delta_1 \geq \delta_2$ indicates that $\delta_1$ is a better or equivalent grade than $\delta_2$. A profile $P : A\times N \rightarrow \triangle$ is a $m$ by $n$ matrix of grades $P \in \triangle^{A \times N}$. Given any $N'\subseteq N$, the operator $\rho: \triangle^{N'} \rightarrow \triangle^{\card{N'}}$ defines an ordering function that given a vector of grades $P_i$ returns the vector ordered by decreasing grades.

Consider a set of alternatives $S\subseteq A$,
%where $|S|=s$ and $s \in \intvl{1,m}$ \textemdash the double brackets represent an interval in the integers. 
we denote by $P^S \in \triangle^{S \times N}$ a restriction of the profile $P$ to only the alternatives in $S$, $P^S \subseteq P$. Note that when $S=A$ then $P^S=P$.
%\commentOC{Could also write $\restr{P}{S × N}$, which leads to more generality, if restricting the users is also sometimes convenient.}

We define $f: \triangle^{N} \rightarrow \triangle$ a function that assigns to any vector of grades a final grade. Given any $S\subseteq A$, a grading function $f^S: \triangle^{S \times N} \rightarrow \triangle^S$ returns a vector of final grades by applying $f$ to every alternative in $S$.
% the \emph{middlemost} aggregation function $f$, for each vector of grades $r_i= (r_1 , \dots, r_n )$ associated to the alternative $i \in \intvl{1,m}$, returns: 
%\begin{align}
%	f(r_i) &= r_{(n+1)/2} \text{ when n is odd,} \\
%	r_{n/2} \geq f(r_i) &\geq r_{(n+2)/2} \text{ otherwise.}
%\end{align}

The \emph{majority-grade}, $f_{maj}$, is the function that associates to a vector of grades $\emptyset \neq q \in \triangle^{N'}, N' \subseteq N$ its median grade value: $f_{maj}(q) = \rho(q)_{\floor{\frac{\card{q}}{2}} + 1}$. Note that in case $\card{q}$ is even two medians could be used, but, as in \citet{Balinski2011} definition, the lower grade is picked. Given any $S\subseteq A$, by applying $f_{maj}$ to all vectors of grades associated to the alternatives in $S$ we obtain the corresponding grading function $f^S_{maj}$. Formally, $f^S_\mathit{maj}(P^S)_i = f_\mathit{maj}(P^S_i)$. The $i$-\emph{th} element of the resulting vector is the median of the ordered vector of grades associated to the $i$-\emph{th} alternative. 
%Because $f^S_{maj}(P^S)_i$ depends only on $P^S_i$ we write $f^S_{maj}(P^S_i)$. \commentOC{I am not sure I follow. You already have a notation for this, namely, $f_\mathit{maj}(P^S_i)$, isn’t it?}
Moreover, when we consider the complete profile (when $S=A$) we will write $f_{maj}(P_i)$ instead of $f^A_{maj}(P^A_i)$.
\commentOC{I doubt that the general $f$ is actually useful, you only seem to use $f$ maj.}
%i.e. it corresponds to the lower middlemost.

Given any $S\subseteq A$, the winner function $F^S_{maj}:\triangle^{S \times N} \rightarrow A$ %$F^S_{maj}:\triangle^{S \times N} \rightarrow 2^A \setminus \emptyset$
is a function that selects the alternative with the highest median grade as winner. We can define it as $F^S_{maj}(P^S) = \argmax_{i\in S}\rho(P^S_i)_{\floor{\frac{n}{2}}+ 1}$ assuming it is a singleton. For brevity, we will write $F_{maj}$ when considering $S=A$. Consider the case when it is not a singleton, this means that two or more alternatives are associated with the same highest median grade $h=\max_{i\in S}\rho(P^S_i)_{\floor{\frac{n}{2}} + 1}$. In this case ties are broken by removing one $h$ grade from the vectors of grades of each tied alternative, recomputing the new median grade and repeating the process until one unique winner is found or there are no more grades to remove. When $n$ is odd, this is equivalent to take the next element after the median, i.e. the one at index $(\floor{\frac{n}{2}} + 1) +1$, if there is still a tie we then look at the previous element before the median, i.e. the one at index $(\floor{\frac{n}{2}} + 1) -1$, and keep alternating until the tie is broken or there are no more elements in the vector. When $n$ is even the process is similar but we alternate starting from the element before the median, $\floor{\frac{n}{2}}$, then the one after, $\floor{\frac{n}{2}} + 2$, and so on. \commentOC{Written as it is, I am doubtful about the value of this remark.} If after applying the mechanism there are still ties we break them using an arbitrary ordering defined on all alternatives, e.g. lexicographical order.

Similarly to the winner function, given any $x \in \intvl{1,m}$, we can define a more general \emph{selection function} $F^S_x:\triangle^{S\times N} \rightarrow 2^A \setminus \emptyset$ that selects exactly the $x$ alternatives with the $x$ highest median grades.
\commentOC{$F^S_x(P^S) = f^S_\mathit{maj}(P^S) \cup f^{S'}_\mathit{maj}(P^{S'}) …$.}

\subsection{Incomplete Knowledge}
In order to analyze the elicitation procedure used by LaPrimaire.org, we need to adapt the notation just described to incomplete profiles. 
\commentOC{Defining the right, full notations from the start would be more gentle for the reader.} \commentBN{To discuss, I think at the end we decided to keep it like this?} Let $\Pbar$ be our knowledge about the profile $P$.
The voters have full knowledge of their own judgments but we ignore them; our goal is to elicit them by questioning the voters starting from zero knowledge.
We introduce an additional grade $\dbar$, and, given a language $\Delta$, $\dbar< \delta, \forall \delta \in \Delta$. \commentBN{I think we should avoid to say this but rather add in $\bar{F}$ that the $\dbar$ are excluded.} The common language in the incomplete knowledge setting is then $\overline{\triangle}=\triangle \cup \dbar$. Voters cannot use this grade to express their judgment over an alternative and it does not count in the computation of the median grade as we will explain formally. We refer to the grades in $\triangle$, the ones used by voters, as "defined" grades.

The starting knowledge is represented by a matrix $m\times n$ of $\dbar$ grades. Given $k \in \N$, we define with $K_j \subseteq A$ a set of $k$ alternatives that we ask the voter $j\in N$ to judge. 
After having asked every voter in $N$ to judge $k$ candidates, we obtain an \emph{incomplete profile} $\overline{P}\in \overline{\triangle}^{A \times N}$, that is a matrix $m \times n$ of grades of which $kn$ are "defined".
Note that when $k=n$ the resulting profile $\overline{P}$ corresponds to the complete profile $P$. Let $C(\overline{P}) = \{P' \in \triangle^{m \times n} \suchthat \overline{P} \subseteq P'\}$ be the set of all completions of $\overline{P}$ obtained by substituting all $\dbar$ grades with "defined" ones, note that $P \in C(\overline{P})$.
\commentOC{Technically that’s not correct as $P$bar may contain some “undefined”, in which case $P$ can’t be a superset of it. (Can be left as is for now.) Also, I suppose that $P$ should keep the identities of the alternatives and voters.}
 
If $K_j=K_l, \forall j,l\in N$, i.e. if we ask all voters to judge the same $k$ alternatives, then we have complete knowledge restricted to this set of candidates. As defined in \Cref{sec:complete}, we call $P^{K_j}$ the restriction of the complete profile $P$ to only the alternatives in $K_j$.
\commentOC{I wonder if this notation will be useful.}

Let $g:\overline{\triangle}^N\rightarrow \bigcup_{N' \subseteq N}\triangle^{N'}$ be a function that given an incomplete vector of grades $q \in \overline{\triangle}^N$, thus $q \subseteq N × \bar{\triangle}$, returns the vector composed only of the "defined" grades $g(q) = \restr{q}{N × \triangle}$.

%The operator $\overline{\rho}$ defines a restricting ordering function that given $\overline{P_i}$, an incomplete vector of $n$ grades, returns the correspondent complete vector restricted to its $x$ "defined" grades decreasingly ordered: $\overline{\rho}(\overline{P_i})=\rho(d(\overline{P_i}))$. \commentBN{Not sure this is necessary.}

Given any $S \subseteq A$, the \emph{majority-grade} for incomplete profile $\overline{f}^S_{maj}: (\bigcup_{x \in \intvl{1,n}}\triangle^{x})^S \rightarrow \triangle^S$ corresponds to $f^S_{maj}$ that only considers the "defined" grades in the computation of the median. Indeed, consider an incomplete profile $\overline{P^S}$ and denote by $P'_i=g(\overline{P}^S_i)$, then ${f}_{maj}(P'_i) = \rho(P')_{\floor{\frac{\card{P'}}{2}} + 1}$, $\forall i \in S$.
\commentOC{I suppose you mean to apply $\rho$ on $P'_i$. Also, your definition makes sense more generally for any $P'_i$ of the right type, not just when $P'_i = g(…)$. In fact, this $f$ is already defined!}

To summarize, starting with zero knowledge, we ask the voters to judge $k$ candidates. Given the partial information at our disposal, we are able to define the "known" median grade for each alternative. We can now use the \emph{selection function} $F^S_k$, defined in \Cref{sec:complete}, to select the $k$ alternatives with the highest "known" median grades.

Given the set $\tilde{K}=F^S_k(g(\overline{P}^S_i))$ of the best $k$ alternatives, every voter is then asked to judge all the candidates in $\tilde{K}$. 
\commentOC{$i$ is not defined; and there may be a type incompatibility between the result of $g$ and the domain of $F^S_k$.}

This process results in a restriction $P^{\tilde{K}}$ of the complete profile $P$. It is important to mention that when we ask the voters to judge an alternative $i\in \tilde{K}$ we assume that they report their preference as they would have stated it when asked about $P$. In other words, $P^{\tilde{K}}_{i} = P_i$ for any $i \in \tilde{K}$.
\commentOC{The formal part of this does not look like your informal hypothesis.}

Please note that $P^{\tilde{K}}$ is a complete matrix of $kn$ grades and that we fall back to the complete profile case, thus, we apply the \emph{majority-grade}, $f^{\tilde{K}}_{maj}$, function to $P^{\tilde{K}}$ to determine the median grades and then the winner function $F^{\tilde{K}}_{maj}$ to select the winner. 
%For simplicity we denote by $\overline{W}_{\overline{P^k}} \subseteq A$ the results of this process.

\begin{remark}
	Because we are interested into investigating \acs{MJ}, we are going to use an alphabet with the same size of the one proposed by \citet{Balinski2011} which is composed of the following adjectives: Excellent, Very good, Good, Average, Mediocre, Inadequate, To be Rejected. For brevity we are gonna rename those adjectives respectively from $\delta_7$, corresponding to Excellent, to $\delta_1$, corresponding to To be Rejected. Therefore, $\triangle=\{\delta_1,\delta_2, \delta_3,\delta_4,\delta_5,\delta_6,\delta_7\}$ 
\end{remark}

Once having defined the notation, the first question that comes to mind is about the risks of incomplete knowledge. Given a profile which we only partially know, would we always select the same set of alternatives as winners in case of complete and incomplete knowledge?
\commentOC{The phrasing of this question could be improved: as stated, the answer is, I suppose, obviously negative. With low knowledge, there is not much hope that the right alternatives would be selected.}

\begin{proposition}
	\label{prop:notsamewinner}
	Given $A$ a set of $m\geq 3$ alternatives and $N$ a set of $n\geq3$ voters, there exist a complete profile $P$ and an incomplete profile $\Pbar \subset P$, such that $F_{maj}(P) \nsubseteq F^{\tilde{K}}_{maj}(P^{\tilde{K}})$ \textemdash where $\tilde{K}=F^S_k(g(\Pbar^S_i))$.
	\commentOC{As proof I’d suggest: assume we never ask about some alternative $i$ which is judged excellent by everybody; and all the other ones are judged the worst.}
\end{proposition}
\begin{proof}
	Pick an alternative $i\in A$ and a voter $j \in N$, let us build a profile $P$ in the following way: the voter $j$ judges $\delta_1$ the alternative $i$ and she judges $\delta_2$ all the other alternatives $x \in A \setminus \{i\}$; every other voter $y\in N \setminus \{j\}$ judges $\delta_7$ the alternative $i$ and $\delta_6$ all the other alternatives $x \in A \setminus \{i\}$. The resulting profile $P$ will have the form:
	\begin{center}
		$
		\begin{array}{ccccccc}
			& j_1 & j_2 & \dots & j & \dots & j_n \\
			i_1 &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
			i_2 &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
			. &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
			i &	\delta_7 & \delta_7 & \dots & \delta_1 & \dots & \delta_7 \\
			. &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
			i_m &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
		\end{array} \quad.
		$
	\end{center}
	For $n\geq 3$ the median grade $f_{maj}(P_i)=\delta_7$ and $f_{maj}(P_x)=\delta_6, \forall x \in A \setminus \{i\}$. Thus, the winner $F_{maj}(P)=\{i\}$.
	
	Consider now any $k \in \intvl{1,m-1}$, and remove from $P$ as many judgments as necessary such that the following conditions are verified: each column only contains $k$ grades \textemdash meaning that each voter judges $k$ candidates \textemdash and the row corresponding to the alternative $i$ is only formed by two grades, one $\delta_7$ and one $\delta_1$ \textemdash we have only the best and worst opinion on $i$. We fill all the unknown judgments with $\dbar$ grades to obtain $\Pbar$. Note that we only have two judgments for the alternative $i$ so $\overline{f}_{maj}(\Pbar_i)=\delta_1$ and, since $m\geq3$ and $1 \leq k \leq m-1$, $\overline{f}_{maj}(\Pbar_x)$ is either $\delta_6$ or $\delta_2$ $\forall x \in A \setminus \{i\}$. Therefore $\overline{f}_{maj}(\Pbar_x) > \overline{f}_{maj}(\Pbar_i)$ $\forall x \in A \setminus \{i\}$, this means that $i$ will not be selected for the second turn, when we ask the voters their complete preferences about the $k$ "best" alternatives. Thus $i \notin \tilde{K}$ and, consequently, $F_{maj}(P) \nsubseteq F^{\tilde{K}}_{maj}(P^{\tilde{K}})$.
\end{proof}


%\section{Reasoning on incompleteness}
%
%Assume that the complete profile $P$ exists but is unknown to us and the knowledge we have is represented by $\overline{P}$. As we observed in \Cref{prop:notsamewinner}, it is possible to elect a candidate as a winner for $\overline{P}$ that would not be selected when considering the complete profile $P$. In this section we want to investigate how likely it is to happen.
%
%Consider $A=\{a,b,c\}$ the set of alternatives, $N=\{v_1,v_2, \dots\}$ the set of voters and $\Delta=\{\delta_1, \dots, \delta_{10}\}$ the common language. We assume that we ask $k=m-1=2$ independently and equiprobably drawn questions to each voter. We denote by $\mathcal{P}(e)$ the probability of the event $e$ to happen.
%
%\commentOC{Please specify that you assume no tie in the highest median grade in these computations.}
%\commentOC{Please write your results as theorems, and the reasoning as a proof. Please specify that the profiles you display are only illustrative, not the general case.}
%
%\paragraph{One voter}
%Consider the following complete profile $P$, because we only have one voter the median of each alternative simply corresponds to the grade assigned from $v_1$.
%\begin{center}
%	$P:
%	\begin{array}{cccc}
%		& v_1 & \quad & f_{maj} \\
%		a &	\delta_{10} &\quad& \delta_{10} \\
%		b &	\delta_5  &\quad& \delta_5 \\
%		c &	\delta_1  &\quad& \delta_1 \\
%	\end{array} \quad, \qquad
%	$
%	$\Pbar:
%	\begin{array}{cccc}
%		& v_1 & \quad & \overline{f}_{maj} \\
%		a &	\reddbar &\quad& \dbar \\
%		b &	\delta_5  &\quad& \delta_5 \\
%		c &	\delta_1  &\quad& \delta_1 \\
%	\end{array} \quad.
%	$
%\end{center}
%
%The alternative $a$ has the highest median thus $a=F_{maj}(P)$. For $a$ not to be the winner of the incomplete profile the only possibility is if we ignore the grade of $a$, thus $\Pbar$ is the only incomplete profile for which $a\neq F_{maj}(\Pbar)$.
%\[\mathcal{P}(a\neq F_{maj}(\Pbar))=1-\frac{k}{m}=\frac{1}{3}.\]
%This means that with one voter we have $\approx 33\%$ of probability to miss the winner selected with complete information.
%\commentOC{Very minor, but I’d write it as a fraction rather than an approximate percentage to make it a precise result.}
%
%\paragraph{Two voters}
%Consider now the following profile $P$ with two voters.
%\begin{center}
%	$P:
%	\begin{array}{ccccc}
%		& v_1 & v_2 & \quad & f_{maj} \\
%		a &	\delta_{10} & \delta_3 & \quad& \delta_3 \\
%		b &	\delta_5 & \delta_2 &\quad& \delta_2 \\
%		c &	\delta_1 & \delta_7 &\quad& \delta_1 \\
%	\end{array} \quad, \qquad
%	$
%\end{center}
%
%The median is the lowest between the two possible value thus $a=F_{maj}(P)$. For $a$ not to be the winner of the incomplete profile there are two possibilities, either we do not know anything about $a$, then $b$ and $c$ are automatically selected for the next phase whatever their medians are 
%\commentOC{I don’t think that this has been specified before.}
%(case $1$: $\overline{P}'$), or the new medians of $b$ and $c$ \commentOC{“new” (and old) is confusing here; I’d write “approximate” (and real)} computed with missing information are higher than the current median of $a$ (case $2$: $\overline{P}^{\second}$). For the case $2$ to happen there are two conditions to be satisfied: the minimum grades of $b$ and $c$ must be missing in the incomplete profile \underline{and} both the maximum grade of $b$ and the maximum grade of $c$ must be greater than the minimum grade of $a$. Note that, because each voter gives her opinion about $k=2$ alternatives, for the former condition to be possible then the minimum grades of $b$ and $c$ must not be assigned by the same voter. 
%
%\begin{center}
%	$\Pbar':
%	\begin{array}{ccccc}
%		& v_1 & v_2 & \quad & \overline{f}_{maj} \\
%		a &	\reddbar & \reddbar & \quad& \dbar \\
%		b &	\delta_5 & \delta_2 &\quad& \delta_2 \\
%		c &	\delta_1 & \delta_7 &\quad& \delta_1 \\
%	\end{array} \quad,
%	$
%	$\Pbar^{\second}:
%	\begin{array}{ccccc}
%		& v_1 & v_2 & \quad & \overline{f}_{maj} \\
%		a &	\delta_{10} & \delta_3 & \quad& \delta_3 \\
%		b &	\delta_5 & \reddbar &\quad& \delta_5 \\
%		c &	\reddbar & \delta_7 &\quad& \delta_7 \\
%	\end{array} \quad.
%	$
%\end{center}
%
%The probability of case $1$, i.e. that $\Pbar_a=\{\dbar,\dbar\}$, is equal to the probability that both voters do not grade $a$, thus $\frac{1}{m}\cdot\frac{1}{m}$. This is necessary and sufficient condition for $a\neq F_{maj}(\Pbar)$. We can decompose the probability of not selecting $a$ in the following way:
%\commentOC{This doesn’t look true.}
%We can decompose the probability of not selecting $a$ in the following way:
%
%\begin{align}
%	\mathcal{P}(a\neq F_{maj}(\Pbar)) &=\overbrace{\mathcal{P}(\Pbar_a=\{\dbar,\dbar\})}^{1/m^2} \overbrace{\mathcal{P}(a\neq F_{maj}(\Pbar)|\Pbar_a=\{\dbar,\dbar\})}^{1}\\
%	&+\underbrace{\mathcal{P}(\Pbar_a\neq\{\dbar,\dbar\})}_{1-1/m^2} \underbrace{\mathcal{P}(a\neq F_{maj}(\Pbar)|\Pbar_a\neq\{\dbar,\dbar\})}_{\color{red}*1}
%\end{align}
%The element denoted by ${\color{red}*1}$ is what we described earlier in case $2$, the probability of both the two following events happening \commentOC{“both events” or “the two following events” (better here), not both the two together}:
%\begin{align}
%	e_1 &= \overline{f}_{maj}(b)=\max{P_{b}} \wedge \overline{f}_{maj}(c)=\max{P_{c}}\\
%	e_2 &= \max{P_{b}}>\min{P_{a}} \wedge \max{P_{c}}>\min{P_{a}}.
%\end{align}	
%\commentOC{For this to make sense we need to assume some distribution over the assignment of grades, so you need to indicate your hypothesis on that (similar to the one over the questions).}
%With this in mind we can again decompose this probability:
%\begin{align}
%	{\color{red}*1} &=\overbrace{\mathcal{P}(e_1 \wedge e_2 |\Pbar_a\neq\{\dbar,\dbar\}) }^{{\color{red}*2}} \overbrace{\mathcal{P}(a\neq F_{maj}(\Pbar)|\Pbar_a\neq\{\dbar,\dbar\}\wedge e_1 \wedge e_2)}^{1}\\
%	&+\mathcal{P}(\lnot(e_1 \wedge e_2) |\Pbar_a\neq\{\dbar,\dbar\}) \underbrace{\mathcal{P}(a\neq F_{maj}(\Pbar)|\Pbar_a\neq\{\dbar,\dbar\}\wedge \lnot (e_1 \wedge e_2))}_{0}
%\end{align}
%As we said earlier for $e_1$ and $e_2$ to happen \commentOC{Do you mean just $e_1$?} it must be that:
%\begin{align}
%	e_3 = &(P_{b,1} = \max{P_{b}} \wedge P_{c,2} = \max{P_{c}}) \vee (P_{b,2} = \max{P_{b}} \wedge P_{c,1} = \max{P_{c}}) .
%\end{align}
%
%\begin{align}
%	{\color{red}*2} &=\overbrace{\mathcal{P}(e_3 |\Pbar_a\neq\{\dbar,\dbar\}) }^{1/2} \overbrace{\mathcal{P}(e_1 \wedge e_2|\Pbar_a\neq\{\dbar,\dbar\}\wedge e_3)}^{{\color{red}*3}}\\
%	&+\mathcal{P}(\lnot e_3 |\Pbar_a\neq\{\dbar,\dbar\}) \underbrace{\mathcal{P}(e_1 \wedge e_2|\Pbar_a\neq\{\dbar,\dbar\}\wedge \lnot e_3)}_{0}
%\end{align}
%\commentOC{This seems not sure to me when considering that two grades can be tied.}
%Because $e_1$ and $e_2$ are two independent events:
%\begin{align}
%	{\color{red}*3} &=\overbrace{\mathcal{P}(e_1 |\Pbar_a\neq\{\dbar,\dbar\}\wedge e_3)}^{{\color{red}*4}} \cdot \overbrace{\mathcal{P}(e_2 |\Pbar_a\neq\{\dbar,\dbar\}\wedge e_3)}^{{\color{red}*5}}
%\end{align}
%
%${\color{red}*4}$ is the probability of picking exactly the alternatives $a$ and $b$ when questioning the voter who assigns $\max{P_{b}}$ and of picking $a$ and $c$ for the other one, thus ${\color{red}*4}=1/m^2$. \commentBN{On the board we wrote $\frac{1}{m^2-1}$ but I don't recall why...I think it's $1/m^2$ no?}
%\commentOC{I believe that $1/m^2$ is $\mathcal{P}(e_1 knowing e_3)$.}
%
%To compute ${\color{red}*5}$ we need to enumerate all the grades orderings such that $\min{P_{a}}>\min{P_{b}}\wedge \min{P_{c}}$, otherwise $a$ would not win in the complete profile \commentOC{You need to specify from the start that $P$ denotes the probability conditioned on $a$ winning.}, and $\max{P_{b}}>\min{P_{a}}\wedge \max{P_{c}}>\min{P_{a}}$. Let us denote the grades given to the alternative $a$ by $\delta_{a_i}$ and $\delta_{a_j}$, and similarly for $b$ and $c$.
%\commentOC{Please specify what $a_i$ and $a_j$ stand for: voters? Considering that $i$ usually designates an alternative, I’d prefer $j$ and $h$, for example, if you need such notation. But aren’t the already known $P^a_1$, $P^a_2$ (or $P_{a, 1}$?) and $\max P_a$ etc. sufficient?}
%\begin{align}
%	\underbrace{\delta_{a_i}>\delta_{b_i}>\delta_{c_i}}_{3!\cdot 2\cdot 2}>\delta_{a_j}>\underbrace{\delta_{b_j}>\delta_{c_j}}_{2}
%\end{align}
%Chosen a grade $a$ ($a_i$ or $a_j$) and a grade $b$ ($b_i$ or $b_j$) as the respective maximums, there are $3!$ way to arrange the maximum grade of each alternative $a, b, c$. Therefore there are $3! \cdot 2 \cdot 2$ combination of grades ordering for this triplet. Note that once we choose $b$ then $c$ is automatic the one given by the other voter because of $e_3$. The position of $\min{P_{a}}$ is fixed for the reason above, and we have already counted the possible exchange $a_i, a_j$ in the previous computation. Last but not least, $\min{P_{b}}$ and $\min{P_{c}}$ can exchange positions, so for each ordering created so far there are two additional way to add the minimums of $b$ and $c$. The total number of orderings of six elements is $6!$, therefore ${\color{red}*5}= \frac{3!\cdot 2\cdot 2\cdot2}{6!}=\frac{1}{15}$.
%\commentOC{This looks quite nice, but I do not understand everything because of the previous point.}
%
%We have now all pieces to compute $\mathcal{P}(a\neq F_{maj}(\Pbar))$. 
%\begin{align}
%	&{\color{red}*3} = \frac{1}{9} \cdot \frac{1}{15} \\
%	&{\color{red}*2} =\frac{1}{2} \cdot \frac{1}{135} \\
%	&{\color{red}*1} =\frac{1}{270} \cdot 1 \\
%	&\mathcal{P}(a\neq F_{maj}(\Pbar)) = \frac{1}{9} \cdot 1 + \frac{8}{9} \cdot \frac{1}{270} \approx 0.11
%\end{align}
%
%This means that with two voters we have $\approx 11\%$ of probability to miss the winner selected with complete information.
%
%\paragraph{Three voters}
%Consider now the following profile $P$ with three voters.
%\begin{center}
%	$P:
%	\begin{array}{cccccc}
%		& v_1 & v_2 &v_3 & \quad & f_{maj} \\
%		a &	\delta_{10} & \delta_5 & \delta_1 & \quad& \delta_5 \\
%		b &	\delta_{10} & \delta_4 & \delta_2 &\quad& \delta_4 \\
%		c &	\delta_{10} & \delta_3 & \delta_3 &\quad& \delta_3 \\
%	\end{array} \quad, \qquad
%	$
%\end{center}
%The alternative with the highest median is $a$ thus $a=\Fmaj(P)$. In a similar vein as the two voters case, for $a$ not to be the winner of the incomplete profile either we do not know any grades of $a$, then $b$ and $c$ are automatically selected for the next phase (case $1$: $\Pbar'$), or, again, the new medians of $b$ and $c$ computed with missing information are higher than the current median of $a$ (case $2$). 
%To understand the conditions necessary for the second case, let us consider the possible new medians of $a$:
%\begin{itemize}
%	\item $\fmajbar(a)= \max{P_a}$: this can happen only if the incomplete vector of $a$ is $\Pbar_a=(\max{P_a},\dbar,\dbar)$, because each voter grades $m-1$ alternatives, this means that we are missing only another grade of the profile. This is not enough to improve the medians of $b$ or $c$, so $a$ will still have the highest median.
%	\item $\fmajbar(a)= \med{P_a}$: this means that either $\Pbar_a=(\max{P_a},\med{P_a},\dbar)$ or $\Pbar_a=(\med{P_a},\dbar,\dbar)$. In the latter, again, one missing grade is not enough to improve the median of other alternatives. Consider the first case and assume that the other two missing grades are $\min{P_b}$ and $\med{P_b}$, assume also that $\max{P_b}>\med{P_a}$. In this case $b$ has a better median than $a$, but $a$ still has a better median than $c$, thus $a$ and $b$ will be selected for the second phase and $a$ will win when discovering the complete information.
%	\item $\fmajbar(a)= \min{P_a}$: this case is the most relevant, and it can happen if $\Pbar_a=(\max{P_a},\dbar,\min{P_a})$, or if $\Pbar_a=(\dbar,\med{P_a},\min{P_a})$ or $\Pbar_a=(\dbar,\dbar,\min{P_a})$. In all of these cases, in order for $a$ not to be selected as winner it must be that $\fmajbar(b)>\min{P_a}$ and  $\fmajbar(c)>\min{P_a}$. However, in the latter case, the value of $\fmajbar(b)$ (respectively $\fmajbar(c)$) can either be $\min{P_b}$ or $\med{P_b}$ ($\min{P_c}$ and $\med{P_c}$) depending on the last grade missing. In the other two cases, we are only missing one grade from $P_a$ thus we could either miss one grade from $P_b$ and one from $P_c$ or both grades from one of those two vectors.
%\end{itemize}
%
%\begin{align}
%	\mathcal{P}(a\neq F_{maj}(\Pbar)) &=\overbrace{\mathcal{P}(\Pbar_a=\{\dbar,\dbar,\dbar\})}^{1/m^3} \overbrace{\mathcal{P}(a\neq F_{maj}(\Pbar)|\Pbar_a=\{\dbar,\dbar,\dbar\})}^{1}\\
%	&+\underbrace{\mathcal{P}(\Pbar_a\neq\{\dbar,\dbar,\dbar\})}_{1-1/m^3} \underbrace{\mathcal{P}(a\neq F_{maj}(\Pbar)|\Pbar_a\neq\{\dbar,\dbar,\dbar\})}_{\color{red}*1}
%\end{align}
% 
%The element denoted by ${\color{red}*1}$ is what we described earlier in the case $\fmajbar(a)= \min{P_a}$, we can decompose it as:
%\begin{align}
%	{\color{red}*1} &=\overbrace{\mathcal{P}(\fmajbar(a)= \min{P_a}|\Pbar_a\neq\{\dbar,\dbar,\dbar\})}^{\frac{3}{m^3-1}} \overbrace{\mathcal{P}(a\neq F_{maj}(\Pbar)|\Pbar_a\neq\{\dbar,\dbar,\dbar\} \wedge \fmajbar(a)= \min{P_a})}^{{\color{red}*2}}\\
%	&+\mathcal{P}(\fmajbar(a)\neq \min{P_a})) |\Pbar_a\neq\{\dbar,\dbar,\dbar\}) \underbrace{\mathcal{P}(a\neq F_{maj}(\Pbar)|\Pbar_a\neq\{\dbar,\dbar,\dbar\} \wedge \fmajbar(a)\neq \min{P_a})}_{0}
%\end{align}
%${\color{red}*2}$ is the probability that $\fmajbar(b)$ and $\fmajbar(c)$ are greater than $\min{P_a}$, thus, that one of these events are true:
%\begin{align}
%	e_1 &= \med{P_{b}}>\min{P_{a}} \wedge \med{P_{c}}>\min{P_{a}}\\
%	e_2 &= \med{P_{b}}>\min{P_{a}} \wedge \min{P_{c}}>\min{P_{a}}\\
%	e_3 &= \min{P_{b}}>\min{P_{a}} \wedge \med{P_{c}}>\min{P_{a}}\\
%	e_4 &= \min{P_{b}}>\min{P_{a}} \wedge \min{P_{c}}>\min{P_{a}}.
%\end{align}	
%Because they are mutually exclusive then:
%	\[{\color{red}*2} =\mathcal{P}(e_1 \vee e_2 \vee e_3 \vee e_4)=\mathcal{P}(e_1)+\mathcal{P}(e_2)+\mathcal{P}(e_3)+\mathcal{P}(e_4)\]
% To compute the probability of these events we need to enumerate all the grades orderings such that the respective events are satisfied. Let us consider $e_1$, and use the same approach used in the two voters case:
% \begin{align}
% 	\underbrace{\delta_{a_i}>\delta_{b_i}>\delta_{c_i}}_{3!\cdot 3^3}>\underbrace{\delta_{a_j}}_{2 \cdot 3}>\underbrace{\delta_{b_j}>\delta_{c_j}}_{2^3}>\underbrace{\delta_{a_k}>\delta_{b_k}>\delta_{c_k}}_{3!}
% \end{align}
% For $e_2$:
% \begin{align}
% 	\underbrace{\delta_{a_i}>\delta_{b_i}>\delta_{c_i}}_{3!\cdot 3^3}>\underbrace{\delta_{a_j}}_{2 \cdot 3}>\underbrace{\delta_{b_j}>\delta_{c_j}}_{2^3}>\underbrace{\delta_{c_k}>\delta_{a_k}>\delta_{b_k}}_{3}
% \end{align}
% For $e_3$:
%\begin{align}
%	\underbrace{\delta_{a_i}>\delta_{b_i}>\delta_{c_i}}_{3!\cdot 3^3}>\underbrace{\delta_{a_j}}_{2 \cdot 3}>\underbrace{\delta_{b_j}>\delta_{c_j}}_{2^3}>\underbrace{\delta_{b_k}>\delta_{a_k}>\delta_{c_k}}_{3}
%\end{align}
% For $e_4$:
% \begin{align}
% 	\underbrace{\delta_{a_i}>\delta_{b_i}>\delta_{c_i}}_{3!\cdot 3^3}>\underbrace{\delta_{a_j}}_{2 \cdot 3}>\underbrace{\delta_{b_j}>\delta_{c_j}>\delta_{b_k}>\delta_{c_k}}_{4!}>\delta_{a_k}
% \end{align}
%
%\begin{align}
%	&{\color{red}*2} =\frac{3^6\cdot2^6+3^6\cdot2^5+3^6\cdot2^5+3^6\cdot2^5}{9!} = \frac{9}{28} \\
%	&{\color{red}*1} =\frac{3}{8} \cdot \frac{9}{28} = \frac{27}{224} \\
%	&\mathcal{P}(a\neq F_{maj}(\Pbar)) = \frac{1}{9} \cdot 1 + \frac{8}{9} \cdot \frac{27}{224} \approx 0.22
%\end{align}
%This means that with three voters we have $\approx 22\%$ of probability to miss the winner selected with complete information.

%\newpage
%\commentBN{Stopped here.}
%\subsection{Unfixed k}
%A natural question that comes to mind when considering the process of asking the voters to judge random alternatives is: how feasible is it? Especially when applying it to political elections, it is safe to say that voters have strong opinions. There are always some candidates that we would never want to see in office, while we would really like to support our favorite candidate. By applying the random selection of questions there is a chance we do not get to express our opinions on those particular candidates. In the worst case, we may be asked to judge only candidates of whom we do not have a strong opinion, or worse, that we do not even know. Is our judgment relevant in this case? How willing are we to take the risk to go and vote without the certainty of being able to express the judgments we consider important?
%
%Because of all these reasons, we may want to consider the possibility for the voters to choose the candidates to judge. One extreme situation that may occur is that each voter judges only its best and worst choice. 
%
%\begin{proposition}
%	Given two integers $k=5$ and $s=5$, $m$ alternatives and $n$ voters who only judge their best and worst candidates, there exist a complete profile $P'$ and an incomplete profile $\overline{P'}$ such that $P'\in C(\overline{P'})$ and $F(P')\neq F(\overline{P'})$.
%\end{proposition}	
%
%\begin{proof} Consider the following complete profile $P$:
%	
%	\begin{center}
%		\begin{tabular}{cccccccc}
%			& j$_1$ & j$_2$ & j$_3$ \\
%			a	&	Average	&	Average	&	Excellent	\\
%			b	&	To be rejected	&	Good	&	Good	\\
%			c	&	Mediocre	&	Excellent	&	Mediocre	\\
%			d	&	Average	&	Average	&	To be rejected	\\
%			e	&	Mediocre	&	To be rejected	&	Mediocre	\\
%			f	&	Excellent	&	Inadequate	&	Inadequate \\
%		\end{tabular}
%	\end{center}
%	
%	
%	for the sake of the example the rows are not ordered vectors because the identity of the voters is considered.
%	
%	The vector of medians $f_{maj}(P)$ is:
%	\begin{center}
%		$
%		\begin{array}{cc}
%			a &	Average \\
%			b &	Good \\
%			c &	Mediocre \\
%			d &	Average	\\
%			e &	Mediocre \\
%			f & Inadequate \\
%		\end{array} \quad.
%		$
%	\end{center}
%	The real winner is $F^P=b$. 
%	
%	Assume that each voter only express its best and worst judgments and construct the complete profile $P'$ from $P$ in the following way: for each alternative $i$ that is not the real winner $w^*$ add as many voters as needed such that its known median grade ($f_{maj}(\overline{P'_i})$) is better than the known median grade of the real winner ($f_{maj}(\overline{P'_{w^*}})$); then add an additional alternative that is rejected by all these new voters. Since the voters only express the best and the worst grades, we are not interested in how they judge the rest of the alternatives, to construct a complete profile we can assume that they judge them according to the current known median. The resulting complete profile $P'$ is the following, but our information $\overline{P'}$ is only restricted to the green values: 
%	
%	\scalebox{0.75}{
%		\begin{tabular}{cccccccc}
%			& j$_1$ & j$_2$ & j$_3$ & j$_4$ & j$_5$ & j$_6$ & j$_7$ \\
%			a	&	Average	&	Average	&	{\color{teal}Excellent}	&	Average	&	Average	&	Average	&	Average	\\
%			b	&	{\color{teal}To be rejected}	&	Good	&	Good	&	Good	&	Good	&	Good	&	Good	\\
%			c	&	Mediocre	&	{\color{teal}Excellent}	&	Mediocre	&	Mediocre	&	Mediocre	&	Mediocre	&	Mediocre	\\
%			d	&	Average	&	Average	&	{\color{teal}To be rejected}	&	{\color{teal}Excellent}	&	{\color{teal}Excellent}	&	Average	&	Average	\\
%			e	&	Mediocre	&	{\color{teal}To be rejected}	&	Mediocre	&	Mediocre	&	Mediocre	&	{\color{teal}Excellent}	&	{\color{teal}Excellent}	\\
%			f	&	{\color{teal}Excellent}	&	Inadequate	&	Inadequate	&	Inadequate	&	Inadequate	&	Inadequate	&	Inadequate	\\
%			g	&	{\color{teal}To be rejected}	&	{\color{teal}To be rejected} & {\color{teal}To be rejected}& {\color{teal}To be rejected} & {\color{teal}To be rejected} & {\color{teal}To be rejected} & {\color{teal}To be rejected}	\\
%		\end{tabular}
%	}
%	
%	The vector of medians $f_{maj}(\overline{P'})$ is:
%	\begin{center}
%		$
%		\begin{array}{cc}
%			a &	\text{Excellent} \\
%			b &	\text{To be rejected} \\
%			c &	\text{Excellent} \\
%			d &	\text{Excellent}	\\
%			e &	\text{Excellent} \\
%			f & \text{Excellent} \\
%			g & \text{To be rejected} \\
%		\end{array} \quad.
%		$
%	\end{center}
%	The real winner $b$ does not appear in the set of candidates for the second round $S=\{a,c,d,e,f\}$, so it will not be elected from the incomplete profile $\overline{P'}$.
%\end{proof}
%
%\section{Questions}
%\begin{itemize}
%	\item Does expressing judgment on randomly selected candidates influence the result? (If we change the questions does the result change?)
%	\item Does the number of questions influence the result? (If we change the number of questions does the result change?)
%	\item If yes, do these effects are mitigated by a second round?
%	\item Which is the right number of questions? (Best trade-off between communication cost and optimal result.)
%	\item Can we select the next question with minimax regret instead of randomly selecting a candidate?
%	\item Can we say anything about the "fairness" of proposing the candidates to judge? Suppose I have strong opinions about only two candidates: one I extremely like and one I extremely dislike. There is a chance I will not be asked about those two candidates, in this case I cannot say much about the other candidates and I am also frustrated because I did not get to express my opinions.
%	\item Consider $n$ voters and $m$ candidates and assume that a voter $i \in N$ judges only a fraction of the $m$ candidates. What is the resulting voting rule? What are its properties? Can a voter manipulate the result by judging only some candidates? 
%\end{itemize}
%
%\section{Old material that can be transformed into examples}
%\begin{proof} Consider $n=3, m=6, k=5$ and the following complete profile $P$:
%	\begin{center}
%		$
%		\begin{array}{cccc}
%			& j_1 & j_2 & j_3 \\
%			a &	Excellent	& Excellent & Inadequate\\
%			b &	Mediocre	& Mediocre	& Mediocre\\
%			c &	Mediocre	& Mediocre & Inadequate\\
%			d &	Average	& Average	& Average\\
%			e &	Average	& Mediocre	& Inadequate \\
%			f &	Average	& Mediocre & Mediocre	  \\
%		\end{array} \quad.
%		$
%	\end{center}
%	The vector of medians $f_{maj}(P)$ is:
%	\begin{center}
%		$
%		\begin{array}{cc}
%			a &	Excellent \\
%			b &	Mediocre \\
%			c &	Mediocre \\
%			d &	Average	\\
%			e &	Mediocre \\
%			f & Mediocre \\
%		\end{array} \quad.
%		$
%	\end{center}
%	The real winner is $F^P=a$. 
%	
%	Consider now the following incomplete profiles $\Pbar$ and $\Pbar'$ obtained after having asked each voter to judge $k=5$ random chosen alternatives: \commentOC{This mixes again the process and the maths. The proposition does not talk about randomness and it is confusing to refer to this here. The proposition holds whatever the way $P$ bar is chosen (including, deterministically).}\commentBN{I'm not sure I got this. With randomness I mean the one in the definition of $\Pbar$.}
%	\begin{center}
%		$\Pbar: \qquad
%		\begin{array}{cccc}
%			& j_1 & j_2 & j_3 \\
%			a &	Excellent	& {\color{red}Undefined} & Inadequate\\
%			b &	Mediocre	& Mediocre	& Mediocre\\
%			c &	Mediocre	& Mediocre & Inadequate\\
%			d &	Average	& Average	& {\color{red}Undefined} \\
%			e &	Average	& Mediocre	& Inadequate \\
%			f &	{\color{red}Undefined}	& Mediocre & Mediocre	  \\
%		\end{array} \quad,
%		$
%	\end{center}
%	\begin{center}
%		$\Pbar': \qquad
%		\begin{array}{cccc}
%			& j_1 & j_2 & j_3 \\
%			a &	Excellent	& Excellent & Inadequate\\
%			b &	Mediocre	& {\color{red}Undefined}	& Mediocre\\
%			c &	Mediocre	& Mediocre & {\color{red}Undefined}\\
%			d &	Average	& Average	& Average \\
%			e &	{\color{red}Undefined}	& Mediocre	& Inadequate \\
%			f &	Average	& Mediocre & Mediocre	  \\
%		\end{array} \quad.
%		$
%	\end{center}
%	The vector of medians are:
%	\begin{center}
%		$f_{maj}(\Pbar)= \quad
%		\begin{array}{cc}
%			a &	Inadequate \\
%			b &	Mediocre \\
%			c &	Mediocre \\
%			d &	Average	\\
%			e &	Mediocre \\
%			f & Mediocre \\
%		\end{array} \quad,\quad%
%		f_{maj}(\Pbar')= \quad
%		\begin{array}{cc}
%			a &	Excellent \\
%			b &	Mediocre \\
%			c &	Mediocre \\
%			d &	Average	\\
%			e &	Inadequate \\
%			f & Mediocre \\
%		\end{array} \quad.
%		$
%	\end{center}
%	
%	Consider the sets of $s=5$ alternatives with the highest median grades for the two profiles, $S'=\{b,c,d,e,f\}$ for $\Pbar$, and $S^{\prime\prime}=\{a,b,c,d,f\}$ for $\Pbar'$, and the two restrictions $P_{S'}$ and $P_{S^{\prime\prime}}$. In particular, $P_{S'}$ corresponds to the complete profile when eliminating the alternative $a$, and $P_{S^{\prime\prime}}$ to the complete profile without the alternative $e$.
%	The vector of medians are:
%	\begin{center}
%		$f_{maj}(P_S')= \quad
%		\begin{array}{cc}
%			b &	Mediocre \\
%			c &	Mediocre \\
%			d &	Average	\\
%			e &	Mediocre \\
%			f & Mediocre \\
%		\end{array} \quad,\quad%
%		f_{maj}(P_S^{\prime\prime})= \quad
%		\begin{array}{cc}
%			a & Excellent \\
%			b &	Mediocre \\
%			c &	Mediocre \\
%			d &	Average	\\
%			f & Mediocre \\
%		\end{array} \quad.
%		$
%	\end{center}
%	The winner associated to the incomplete profile $\Pbar$ is then $F^{P_{S'}} = d$ and the one associated to $\Pbar'$ is $F^{P_{S^{\prime\prime}}} = a$, thus $F^{\Pbar} \neq F^{\Pbar'}$.
%\end{proof}
%\commentOC{Perhaps some part of this could be transformed to an example.}
%
%\begin{corollary}
%	Given $m$ alternatives, $n$ voters and an integer $k \in \intvl{1,m}$, there exist a profile $P$ and an incomplete profile of $P$, $\Pbar$, such that $F^{\Pbar}$ is not the real winner.
%\end{corollary}
%\commentOC{“real winner” is inappropriate here. Is there an unreal winner? I realize that you mean “winner considering the complete profile” VS “winner considering some part of it”, but I don’t think that the term “real” is appropriate. I’d simply say “winners” for the winners of the complete election, and perhaps “approximate winners” for the winners given a partial profile, or something similar.}
%
%\section{Old computations and plots}
%Consider an alternative $w\in A$ and observe that for $w$ to be in $W^*$ we need $f_{maj}(P_w)\geq f_{maj}(P_i), \ \forall i \in A$. 
%Consider now the incomplete profile $\overline{P^k}$ and the set of the $k$ alternatives with the highest "known" median grades $\tilde{K}$. 
%\commentOC{Do you mean, the set $\tilde{K}$ of the $k$ alternatives…?}
%Let $v$ be the $k$-th highest median, i.e. $v=\min_{i\in \tilde{K}} \overline{f}_{maj}(\overline{P_i})$ the lowest grade of an alternative in $\tilde{K}$. If $\overline{f}_{maj}(\Pbar_w) \geq v$ then $w \in \tilde{K}$. 
%\commentOC{A notation for the $x$th median grade or $x$th best alternative would be useful.}\commentBN{ok}
%
%Because the voters express their judgments on all the alternatives in $\tilde{K}$ 
%\commentOC{The reason for this claim is unclear to me. Is this a deduction, or an hypothesis?}\commentBN{Need more clarity, this should be clear.}
%and $P^{\tilde{K}}_{i} = P_i$ for any $i \in \tilde{K}$, then if $w \in W^*$ and $w \in \tilde{K}$ then $w \in \overline{W}_{\overline{P^k}}$.
%
%In order to compute the probability of a winning alternative $w$ to not be elected in case of incompleteness, we need to focus on the probability for $w$ not to reach the second round: probability of $w \notin \tilde{K}$.
%\commentBN{If I'm the winner here are three cases I'm not elected in incompleteness:
%	\begin{itemize}
%		\item I'm demoted $\Rightarrow \overline{h}<h$
%		\begin{itemize}
%			\item others are promoted $\Rightarrow v>\overline{h}$
%			\item or not $\Rightarrow v>\overline{h}$
%		\end{itemize}
%		\item $\overline{h}=h$
%		\begin{itemize}
%			\item others are promoted $\Rightarrow v>\overline{h}$
%		\end{itemize}
%		\item I'm promoted $\Rightarrow \overline{h}>h$
%		\begin{itemize}
%			\item others are promoted $\Rightarrow v>\overline{h}$
%		\end{itemize}
%\end{itemize}}
%
%Consider the complete profile $P$ and the highest median grade $h=\max_{i\in A}\rho(P_i)_{\floor{\frac{n}{2}} + 1}$. Since $w \in W^*$ then $f_{maj}(P_{w})\geq h$ and the vector of grades $P_w$ must be composed of at least $\floor{\frac{n}{2}}+1$ grades $\alpha \geq h$ and at most $\lceil \frac{n}{2}\rceil-1$ of grades $\beta < h$. Let us evaluate the worst case scenario.
%Without loss of generality consider $n$ an odd value, then the vector $P_{w}$ in the worst case contains exactly $\frac{n+1}{2}$ grades greater than or equal to $h$ and $\frac{n-1}{2}$ grades lower than $h$.
%\[P_w : \qquad [ \alpha_1, \dots , \alpha_{\frac{n+1}{2}}, \beta_1, \dots , \beta_{\frac{n-1}{2}} ] \]
%Consider now the incomplete profile $\overline{P^k} \subset P$ and the highest "known" median $v$ described above. For $w \notin \tilde{K}$ then $\overline{f}_{maj}(\overline{P^k}_w) < v$ and the partial vector $\overline{P^k}_w$ of $x\in \intvl{1,n-1}$ defined grades must be composed of at least $\frac{x+1}{2}$ grades $\beta'<v$ and at most $\frac{x-1}{2}$ grades $\alpha' \geq v$. 
%
%If $h=v$, we have $\binom{(n+1)/2}{(x-1)/2}$ ways of picking $\frac{x-1}{2}$ grades greater than or equal to $v$ out of the $\frac{n+1}{2}$ of the original vector; and $\binom{(n-1)/2}{(x+1)/2}$ ways of picking $\frac{x+1}{2}$ grades lower than $v$.
%\begin{align}
%	P_{w}: \qquad [ \underbrace{\alpha_1, \dots , \alpha_{\frac{n+1}{2}}}_{\begin{pmatrix}\frac{n+1}{2} \\ \frac{x-1}{2}\end{pmatrix}}, \underbrace{\beta_1, \dots , \beta_{\frac{n-1}{2}}}_{\begin{pmatrix}\frac{n-1}{2} \\ {\frac{x+1}{2}}\end{pmatrix}} ] \\
%	\overline{P^k}_w:\qquad [ \overbrace{\alpha'_1, \dots , \alpha'_{\frac{x-1}{2}}}, \overbrace{\beta'_1, \dots , \beta'_{\frac{x+1}{2}}}]
%\end{align} 
%\newcommand{\largemath}[1]{{\mathlarger{\mathlarger{\mathlarger{\mathlarger{\mathlarger#1}}}}}}
%%note to myself: find a better way please
%
%We define the probability of $w \notin \tilde{K}$ as the number of incomplete vectors $\overline{P^k}_w$ for which $\overline{f}_{maj}(\overline{P^k}_w) < v$, over the total number of possible incomplete vectors:
%\commentBN{prob of w to be demoted in worst case}
%\[ \largemath{\sum}_{x=1}^{n-1}{ \frac{ \largemath{\sum}_{i=0}^{x/2}{ \begin{pmatrix}\frac{n+1}{2} \\ {\frac{x-1}{2}-i}\end{pmatrix} \cdot \begin{pmatrix}\frac{n-1}{2} \\ {\frac{x+1}{2}+i}\end{pmatrix} }}{\begin{pmatrix}n \\ x\end{pmatrix}} } \]
%
%\commentBN{prob of w to be demoted for $\beta$ going from $j=0$ to $(n-1)/2$}
%
%\[ P(\overline{h}<h)= \largemath{\sum}_{j=0}^{(n-1)/2}{ \ \largemath{\sum}_{x=1}^{n-1}{ \frac{ \largemath{\sum}_{i=0}^{x/2}{ \begin{pmatrix}\frac{n+1}{2}+j \\ {\frac{x-1}{2}-i}\end{pmatrix} \cdot \begin{pmatrix}\frac{n-1}{2}-j \\ {\frac{x+1}{2}+i}\end{pmatrix} }}{\begin{pmatrix}n \\ x\end{pmatrix}} }} \]
%
%\commentBN{prob of w to be promoted for $\alpha$ going from $j=0$ to $(n-1)/2$ where: the vector of grades $P_w$ must be composed of at least $\floor{\frac{n}{2}}+1$ grades $\alpha > h$ and at most $\lceil \frac{n}{2}\rceil-1$ of grades $\beta \leq h$.}
%
%\[ P(\overline{h}>h)= \largemath{\sum}_{j=0}^{(n-1)/2}{ \ \largemath{\sum}_{x=1}^{n-1}{ \frac{ \largemath{\sum}_{i=0}^{x/2}{ \begin{pmatrix}\frac{n-1}{2}-j \\ {\frac{x+1}{2}+i}\end{pmatrix} \cdot \begin{pmatrix}\frac{n+1}{2}+j \\ {\frac{x-1}{2}-i}\end{pmatrix} }}{\begin{pmatrix}n \\ x\end{pmatrix}} }} \]
%
%\commentBN{$P(\overline{h}=h)= 1-P(\overline{h}>h)\cdot P(\overline{h}<h)$ : probability of being properly labeled}
%
%The size $x$ of an incomplete vector $\overline{P_i}$ for $i \in A$, depends on the number of questions $k$ asked to the voters, in fact, if we ask $n$ voters to judge $k$ random alternatives, ideally, each alternative $i$ will be judged $\frac{k\cdot n}{m}$ times. Consider the value $k$ as a function of the number of alternatives: $k=c \cdot m$ where $c \in \R$. If $m=10$ and $k=5$ then $k=1/2 m$, i.e. we ask the voters to judge half of the candidates. Thus, the value $x$ depends only on the number of voters $n$ $x=\frac{k\cdot n}{m}= c \cdot n$, $c\in \R$. Without loss of generality we consider both $x$ and $n$ odd values.
%
%Consider the worst case scenario: the real vector $P_{w^*}$ has a proportion of $51\%-49\%$ of $\alpha-\beta$ grades. \Cref{fig:differentX51-49} shows the probability of electing a non-real winner in this scenario for different size $x$ of the incomplete vector $\overline{P_{w^*}}$. \Cref{tab:differentX51-49} shows in details those values. Note that when $x=1001$ the probability is about $25\%$, but we should keep in mind that $x= c \cdot n$, thus a vector of size $1000$ means that the alternative $w^*$ was judged by only $1/10$ of the voters. With this in mind, we see that with $x=\frac{n}{2}$ we obtain a very low probability of only $2.12\%$, but we need $4/5$ of the voters to judge each alternative to get zero probability of "miss-qualification".
%
%The situation change drastically for different proportions of $\alpha-\beta$ grades as \Cref{fig:differentX} shows. In particular, we only need about $200$ judgments (thus $1/50$n) to reach an almost zero probability of electing a non real winner when the real vector $P_{w^*}$ has a proportion of $60\% \alpha -40\% \beta$ grades. Recalling the formula:
%\begin{align}
%	x&=\frac{k \cdot n}{m} \\
%	200&=\frac{k}{m}\cdot 10000 \\
%	\frac{1}{50}&=\frac{k}{m} \\
%	k&=\frac{m}{50}
%\end{align}
%we note that asking one question per voter is more than enough to avoid the election of a non-real winner.
%
%In the 2016 elections organised by LaPrimaire.org $n=10675$ voters participated in the first round, and each of them judged $k=5$ random alternatives out of the $m=12$ total ones. Each alternative received an average of $4449$ judgments. Using this data, we simulated th probability of electing a non-real winner for different proportions of $\alpha-\beta$ grades. \Cref{fig:original} and \Cref{tab:original} show the results.
%
%By crossing these results we note that we could have asked the voters far less than $5$ questions, reducing the communication and the cognitive cost of the elicitation process.
%
%%xticklabel style = {font=\footnotesize},
%%x label style={at={(axis description cs:0.5,-0.05)},anchor=north}
%\begin{figure}
%	\centering
%	\begin{tikzpicture}
%		\begin{axis}[
%			ylabel=Prob. \%,
%			xlabel= x,
%			ymin=0,
%			ymax=50,
%			xmin=1,
%			xmax=10001,
%			xtick={1,1001,2001,3001,4001,5001,6001,7001,8001,9001,10001},
%			xticklabels={$10^{-3}$,1,2,3,4,5,6,7,8,9,10},
%			xticklabel style = {yshift=-0.5ex},
%			scaled x ticks= real:1000,
%			x label style={at={(axis description cs:0.5,-0.03)},anchor=north}
%			]
%			\addplot[thick, blue] table [x=x, y=ProbOfMiss, col sep=comma]{data/test/51-49-100.csv};			
%		\end{axis}
%	\end{tikzpicture}
%	\caption{Probability of electing a non-real winner, for different values of $x$, with $n=10000$, and $51\%-49\%$ proportion of $\alpha - \beta$ grades.}
%	\label{fig:differentX51-49}
%\end{figure}
%
%\sisetup{table-number-alignment = center, table-figures-integer=2, table-figures-decimal=1, table-auto-round}
%\begin{table}
%	\centering
%	\begin{tabular}{S[table-figures-integer=5, table-figures-decimal=0]S[table-figures-integer=2, table-figures-decimal=2]}
%		\toprule
%		{x} & {Prob. of Miss} \\
%		\midrule
%		1	&	48.9853044087	\\
%		1001	&	24.9190117413	\\
%		2001	&	15.5009678852	\\
%		3001	&	9.1920240364	\\
%		4001	&	4.8710050444	\\
%		5001	&	2.1180123415	\\
%		6001	&	0.645530701	\\
%		7001	&	0.096388706	\\
%		8001	&	0.0024354987	\\
%		9001	&	0.000000051	\\
%		10001	&	0.00	\\
%		\bottomrule
%	\end{tabular}
%	\caption{Detailed numbers of \Cref{fig:differentX51-49}.}
%	\label{tab:differentX51-49}
%\end{table}
%
%\begin{figure}
%	\centering
%	\begin{tikzpicture}
%		\begin{axis}[
%			ylabel=Prob. \%,
%			xlabel= x,
%			ymin=0,
%			ymax=50,
%			xmin=1,
%			xmax=201,
%			enlarge x limits=-1, %hack to plot on the full x-axis scale
%			width=13cm, %set bigger width
%			height=6cm,
%			legend style={font=\scriptsize}
%			]
%			\addlegendimage{mark=*,teal,mark size=1.5}
%			\addlegendimage{mark=triangle*,orange,mark size=1.5}
%			\addlegendimage{mark=square*,blue,mark size=1.5}
%			\addlegendimage{mark=diamond*,red,mark size=1.5}
%			
%			\addplot[thick, mark=*, mark size = {2}, mark indices = {15}, teal] table [x=x, y=ProbOfMiss, col sep=comma]{data/test/60-40-2.csv};
%			\addlegendentry{$60\%-40\%$}
%			\addplot[thick, mark=triangle*, mark size = {2}, mark indices = {6}, orange] table [x=x, y=ProbOfMiss, col sep=comma]{data/test/70-30-2.csv};
%			\addlegendentry{$70\%-30\%$}	
%			\addplot[thick, mark=square*, mark size = {2}, mark indices = {4}, blue] table [x=x, y=ProbOfMiss, col sep=comma]{data/test/80-20-2.csv};	
%			\addlegendentry{$80\%-20\%$}
%			\addplot[thick, mark=diamond*, mark size = {2}, mark indices = {2}, red] table [x=x, y=ProbOfMiss, col sep=comma]{data/test/90-10-2.csv};			
%			\addlegendentry{$90\%-10\%$}
%		\end{axis}
%	\end{tikzpicture}
%	\caption{Probability of electing a non-real winner, for different values of $x$ and different proportion of $\alpha - \beta$ grades, with $n=10000$.}
%	\label{fig:differentX}
%\end{figure}
%
%
%\begin{figure}
%	\centering
%	\begin{tikzpicture}
%		\begin{axis}[
%			ylabel=Prob. of Miss \%,
%			xlabel=Percentage of $\alpha$ Grades \%,
%			ymin=0,
%			ymax=5,
%			xmin=5445,
%			xmax=9608,
%			scaled ticks = false,
%			xtick={5445,6405,7473,8540,9608},
%			xticklabels={51,60,70,80,90}
%			]
%			\addplot[thick, red] table [x=BetterThanMed, y=ProbOfMiss, col sep=comma]{data/test/original.csv};			
%		\end{axis}
%	\end{tikzpicture}
%	\caption{Probability of electing a non-real winner, for $n=10675$, $x=4449$ and different proportion of $\alpha - \beta$ grades.}
%	\label{fig:original}
%\end{figure}
%
%\begin{table}
%	\centering
%	\begin{tabular}{cc}
%		\toprule
%		{$\alpha-\beta$} & {Prob. of Miss} \\
%		\midrule
%		$51\%-49\%$	&	3.92	\\
%		$60\%-40\%$	&	2.79$10^{-69}$	\\
%		$70\%-30\%$	&	5.80$10^{-318}$	\\
%		$80\%-20\%$	&	0.00	\\
%		$90\%-10\%$	&	0.00	\\
%		\bottomrule
%	\end{tabular}
%	\caption{Detailed numbers of \Cref{fig:original}.}
%	\label{tab:original}
%\end{table}
%
